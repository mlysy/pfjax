
@article{malik.pitt11,
	title = {Particle filters for continuous likelihood evaluation and maximisation},
	volume = {165},
	issn = {03044076},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0304407611001473},
	doi = {10.1016/j.jeconom.2011.07.006},
	abstract = {In this paper, a method is introduced for approximating the likelihood for the unknown parameters of a state space model. The approximation converges to the true likelihood as the simulation size goes to infinity. In addition, the approximating likelihood is continuous as a function of the unknown parameters under rather general conditions. The approach advocated is fast and robust, and it avoids many of the pitfalls associated with current techniques based upon importance sampling. We assess the performance of the method by considering a linear state space model, comparing the results with the Kalman filter, which delivers the true likelihood. We also apply the method to a non-Gaussian state space model, the stochastic volatility model, finding that the approach is efficient and effective. Applications to continuous time finance models and latent panel data models are considered. Two different multivariate approaches are proposed. The neoclassical growth model is considered as an application.},
	number = {2},
	journal = {Journal of Econometrics},
	author = {Malik, Sheheryar and Pitt, Michael K.},
	year = {2011},
	pages = {190--209}
}

@incollection{doucet.johansen09,
	address = {Cambridge},
	title = {A tutorial on particle filtering and smoothing: {Fifteen} years later},
	booktitle = {Handbook of {Nonlinear} {Filtering}},
	publisher = {Cambridge University Press},
	author = {Doucet, Arnaud and Johansen, Adam M.},
	editor = {Crisan, D. and Rozovsky, B.},
	year = {2009}
}


@article{poyiadjis.etal11,
	title = {Particle approximations of the score and observed information matrix in state space models with application to parameter estimation},
	volume = {98},
	issn = {0006-3444, 1464-3510},
	url = {https://academic.oup.com/biomet/article-lookup/doi/10.1093/biomet/asq062},
	doi = {10.1093/biomet/asq062},
	abstract = {Particle methods are popular computational tools for Bayesian inference in nonlinear nonGaussian state space models. For this class of models, we present two particle algorithms to compute the score vector and observed information matrix recursively. The first algorithm is implemented with computational complexity O(N ) and the second with complexity O(N 2), where N is the number of particles. Although cheaper, the performance of the O(N ) method degrades quickly, as it relies on the approximation of a sequence of probability distributions whose dimension increases linearly with time. In particular, even under strong mixing assumptions, the variance of the estimates computed with the O(N ) method increases at least quadratically in time. The more expensive O(N 2) method relies on a nonstandard particle implementation and does not suffer from this rapid degradation. It is shown how both methods can be used to perform batch and recursive parameter estimation.},
	language = {en},
	number = {1},
	journal = {Biometrika},
	author = {Poyiadjis, G. and Doucet, A. and Singh, S. S.},
	year = {2011},
	pages = {65--80}
}


@inproceedings{cappe.moulines05,
	title = {On the use of particle filtering for maximum likelihood parameter estimation},
	abstract = {Particle ﬁltering – perhaps more properly named Sequential Monte Carlo – approaches have a strong potential for signal and image processing applications. A problem of great practical signiﬁcance in this ﬁeld, which remains largely unsolved as of today, is the estimation of ﬁxed model parameters based on the output of sequential simulations.},
	booktitle = {13th European Signal Processing Conference},
	author = {Cappé, Olivier and Moulines, Eric},
	year = {2005},
	pages = {1--4}
}


@inproceedings{corenflos.etal21,
	series = {Proceedings of machine learning research},
	title = {Differentiable particle filtering via entropy-regularized optimal transport},
	volume = {139},
	url = {https://proceedings.mlr.press/v139/corenflos21a.html},
	abstract = {Particle Filtering (PF) methods are an established class of procedures for performing inference in non-linear state-space models. Resampling is a key ingredient of PF necessary to obtain low variance likelihood and states estimates. However, traditional resampling methods result in PF-based loss functions being non-differentiable with respect to model and PF parameters. In a variational inference context, resampling also yields high variance gradient estimates of the PF-based evidence lower bound. By leveraging optimal transport ideas, we introduce a principled differentiable particle filter and provide convergence results. We demonstrate this novel method on a variety of applications.},
	booktitle = {Proceedings of the 38th international conference on machine learning},
	publisher = {PMLR},
	author = {Corenflos, Adrien and Thornton, James and Deligiannidis, George and Doucet, Arnaud},
	editor = {Meila, Marina and Zhang, Tong},
	year = {2021},
	pages = {2100--2111}
}


@article{gordon.etal93,
	title = {Novel approach to nonlinear/non-{Gaussian} {Bayesian} state estimation},
	volume = {140},
	issn = {0956375X},
	url = {https://digital-library.theiet.org/content/journals/10.1049/ip-f-2.1993.0015},
	doi = {10.1049/ip-f-2.1993.0015},
	abstract = {An algorithm, the bootstrap filter, is proposed for implementing recursive Bayesian filters. The required density of the state vector is represented as a set of random samples, which are updated and propagated by the algorithm. The method is not restricted by assumptions of linearity or Gaussian noise: it may be applied to any state transition or measurement model. A simulation example of the bearings only tracking problem is presented. This simulation includes schemes for improving the efficiency of the basic algorithm. For this example, the performance of the bootstrap filter is greatly superior to the standard extended Kalman filter.},
	number = {2},
	journal = {IEE Proceedings-F},
	author = {Gordon, N.J. and Salmond, D.J. and Smith, A.F.M.},
	year = {1993},
	pages = {107--113}
}
