{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GC Unit Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax\n",
    "from jax import random\n",
    "import jax.numpy as jnp\n",
    "\n",
    "# again, this only works on startup!\n",
    "from jax.config import config\n",
    "config.update(\"jax_enable_x64\", True)\n",
    "\n",
    "import pfjax as pf\n",
    "from pfjax import particle_resamplers as resampler\n",
    "from pfjax.utils import lwgt_to_prob, weighted_corr, argsort_marginal, continuous_cdf, interpolate_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resample_gaussian_copula(key, x_particles_prev, logw):\n",
    "    r\"\"\"\n",
    "    Particle resampler with Gaussian Copula distribution.\n",
    "\n",
    "    Estimate and sample from a Gaussian copula as follows: \n",
    "        - Find Y = (F_1(X_1), ..., F_d(X_d))\n",
    "        - rho_hat = weighted correlation of Y \n",
    "        - Sample Z ~ N(0, rho_hat) N times\n",
    "        - Create U = (phi(Z_1), ..., phi(Z_d))\n",
    "        - Use inverse-CDF of marginals to create samples: (inv-CDF(U_1), ..., inv-CDF(U_d))\n",
    "\n",
    "    Args: \n",
    "        key: PRNG key\n",
    "        x_particles_prev: An `ndarray` with leading dimension `n_particles` consisting of the particles from the previous time step.\n",
    "        logw: Vector of corresponding `n_particles` unnormalized log-weights.\n",
    "\n",
    "    Returns: \n",
    "        A dictionary with elements:\n",
    "            - `x_particles`: An `ndarray` with leading dimension `n_particles` consisting of the particles from the current time step.  These are sampled with replacement from `x_particles_prev` with probability vector `exp(logw) / sum(exp(logw))`.\n",
    "            - `ancestors`: Vector of `n_particles` integers between 0 and `n_particles-1` giving the index of each element of `x_particles_prev` corresponding to the elements of `x_particles`.\n",
    "\n",
    "    TODO: \n",
    "        - Should be able to use jnp.take() with the `continuous_cdf` block and remove a vmap\n",
    "    \"\"\"\n",
    "    p_shape = x_particles_prev.shape\n",
    "    n_particles = p_shape[0]\n",
    "    x_particles = x_particles_prev.reshape((n_particles, -1))\n",
    "    d = x_particles.shape[-1]\n",
    "    prob = lwgt_to_prob(logw)\n",
    "    \n",
    "    # sort marginals: \n",
    "    sorted_marginals = jax.vmap(\n",
    "        argsort_marginal,\n",
    "        in_axes = (1, None)\n",
    "    )(x_particles, prob)\n",
    "\n",
    "    # estimate correlation matrix: \n",
    "    Y = jax.vmap(\n",
    "        lambda x, sorted_x, sorted_w: quantile_func(x, sorted_samples=sorted_x, cumulative_weights=jnp.cumsum(sorted_w)),\n",
    "        in_axes = (0, 0, 0))(sorted_marginals[\"unsorted_x\"], sorted_marginals[\"x\"], sorted_marginals[\"w\"])\n",
    "\n",
    "    rho_hat = weighted_corr(Y, weights = prob)\n",
    "\n",
    "    # gaussian copula: \n",
    "    Z = random.multivariate_normal(key=key, mean = jnp.zeros(d), cov = rho_hat, shape = (n_particles,))\n",
    "    U = jax.scipy.stats.norm.cdf(Z)\n",
    "\n",
    "    interpolated_weights = jax.vmap(interpolate_weights, in_axes = (0,))(sorted_marginals[\"w\"])\n",
    "\n",
    "    x_samples = jax.vmap(\n",
    "        lambda x, w, u: jax.vmap(\n",
    "            continuous_cdf,\n",
    "            in_axes= (None, None, 0)\n",
    "        )(x, w, u),\n",
    "        in_axes = (0, 0, 1))(sorted_marginals[\"x\"], interpolated_weights, U)\n",
    "\n",
    "    return {\n",
    "        \"x_particles\": jnp.reshape(jnp.transpose(x_samples), newshape=p_shape)\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.5        0.16666667 1.        ]\n",
      "[0.5        0.16666667 1.        ]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "## quantile function: \n",
    "def quantile_func_ (X, W):\n",
    "    \"\"\" Find the quantile for each sample, X \"\"\"\n",
    "    q = np.zeros(len(X))\n",
    "    for i in range(len(X)):\n",
    "        q[i] = sum(W[X <= X[i]])\n",
    "    return q\n",
    "\n",
    "def quantile_func (x, sorted_samples, cumulative_weights):\n",
    "    \"\"\"\n",
    "    x: vector of points to evaluate cdf\n",
    "    cdf: {\"x\": sorted samples\n",
    "          \"w\": cumulative sum of weights}\n",
    "    \"\"\"\n",
    "    cdf_fn = np.vectorize(lambda y: cumulative_weights[np.argmax(sorted_samples == y)])\n",
    "    return cdf_fn(x)\n",
    "\n",
    "x = np.array([5,2,10])\n",
    "w = np.array([2/6, 1/6, 3/6])\n",
    "ind = np.argsort(x)\n",
    "\n",
    "print(quantile_func_(x, w))\n",
    "print(quantile_func(x = x, \n",
    "                     sorted_samples = x[ind],\n",
    "                     cumulative_weights = np.cumsum(w[ind])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.5        0.16666667 1.        ]\n",
      "[0.5        0.16666667 1.        ]\n"
     ]
    }
   ],
   "source": [
    "rho_hat = weighted_corr(Y, weights = prob)\n",
    "\n",
    "def weighted_corr (X, weights):\n",
    "    r\"\"\"\n",
    "    Return weighted correlation matrix\n",
    "    \"\"\"\n",
    "    corr_mat = jnp.cov(X, aweights = weights)\n",
    "    stddevs = jnp.sqrt(jnp.diag(corr_mat))\n",
    "    corr_mat = corr_mat / stddevs[:, None] / stddevs[None, :]\n",
    "    return corr_mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plain jnp Gaussian Copula: \n",
    "\n",
    "def marginal_cdf (x, data, weights):\n",
    "    r\"\"\"\n",
    "    Return quantile of x given data and weights\n",
    "    \"\"\"\n",
    "    return sum(jnp.where(data < x, x = weights, y=0))\n",
    "\n",
    "def custom_gc(key, x_particles_prev, logw):\n",
    "    r\"\"\"\n",
    "    Particle resampler with Gaussian Copula distribution.\n",
    "\n",
    "    Estimate and sample from a Gaussian copula as follows: \n",
    "        - Find Y = (F_1(X_1), ..., F_d(X_d))\n",
    "        - rho_hat = weighted correlation of Y \n",
    "        - Sample Z ~ N(0, rho_hat) N times\n",
    "        - Create U = (phi(Z_1), ..., phi(Z_d))\n",
    "        - Use inverse-CDF of marginals to create samples: (inv-CDF(U_1), ..., inv-CDF(U_d))\n",
    "    \"\"\"\n",
    "    p_shape = x_particles_prev.shape\n",
    "    n_particles = p_shape[0]\n",
    "    x_particles = x_particles_prev.reshape((n_particles, -1))\n",
    "    d = x_particles.shape[-1]\n",
    "    prob = lwgt_to_prob(logw)\n",
    "\n",
    "    # estimate correlation matrix: \n",
    "    Y = jax.vmap(\n",
    "        lambda x: \n",
    "        jax.vmap(\n",
    "            marginal_cdf,\n",
    "            in_axes = (0, None, None)\n",
    "        )(x, x, prob),\n",
    "        in_axes = (1))(x_particles)\n",
    "    rho_hat = weighted_corr(Y, weights = prob)\n",
    "\n",
    "    # gaussian copula: \n",
    "    Z = random.multivariate_normal(key=key, mean = jnp.zeros(d), cov = rho_hat, shape = (n_particles,))\n",
    "    U = jax.scipy.stats.norm.cdf(Z)\n",
    "\n",
    "    sorted_marginals = jax.vmap(\n",
    "        argsort_marginal,\n",
    "        in_axes = (-1, None)\n",
    "    )(x_particles, prob)\n",
    "\n",
    "    interpolated_weights = jax.vmap(interpolate_weights, in_axes = (0,))(sorted_marginals[\"w\"])\n",
    "    x_samples = jax.vmap(\n",
    "        lambda x, w, u: jax.vmap(\n",
    "            continuous_cdf,\n",
    "            in_axes= (None, None, 0)\n",
    "        )(x, w, u),\n",
    "        in_axes = (0, 0, 1))(sorted_marginals[\"x\"], interpolated_weights, U)\n",
    "\n",
    "    return {\n",
    "        \"x_particles\": jnp.reshape(jnp.transpose(x_samples), newshape=p_shape)\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gaussian Copula Resampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import norm\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "import pandas as pd\n",
    "\n",
    "import jax\n",
    "from jax import random\n",
    "import jax.numpy as jnp\n",
    "# from jax.experimental import checkify\n",
    "from functools import partial\n",
    "\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "sns.set()\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# again, this only works on startup!\n",
    "from jax.config import config\n",
    "config.update(\"jax_enable_x64\", True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "@jax.jit\n",
    "def continuous_cdf (xs, pi, u):\n",
    "    \"\"\"\n",
    "    Return one sample from a continuous approximation of the ECDF of x.\n",
    "    \n",
    "    Should bbe trivial to extend to multiple samples if needed by: \n",
    "        list(map(lambda x: np.argmax(w_cdf > x), u))\n",
    "        \n",
    "    \"\"\"\n",
    "#     checkify.check(jnp.sum(weights) == 1, \"weights must sum to 1\")\n",
    "    n = len(xs)\n",
    "\n",
    "    w_cdf = jnp.cumsum(pi)\n",
    "    r = np.argmax(w_cdf > u)\n",
    "    u_new = (u - w_cdf[r-1]) / pi[r]\n",
    "    \n",
    "    # select region: \n",
    "    new_x = jax.lax.cond(\n",
    "        r == 0,\n",
    "        lambda _: xs[0],\n",
    "        lambda _: jax.lax.cond(\n",
    "            r == n,\n",
    "            lambda _: xs[-1],\n",
    "            lambda _: (xs[r] - xs[r-1]) * u_new + xs[r-1],\n",
    "            r\n",
    "        ),\n",
    "        r\n",
    "    )\n",
    "    return new_x\n",
    "\n",
    "\n",
    "def interpolate_weights (weights):\n",
    "    \"\"\" Interpolate weights as in Malik&Pitt \"\"\"\n",
    "    n = len(weights) \n",
    "    pi = jnp.zeros(n + 1)\n",
    "    pi = pi.at[0].set(weights[0] / 2)\n",
    "    pi = pi.at[n].set(weights[-1] / 2)\n",
    "    pi = pi.at[1:n].set((weights[:-1] + weights[1:]) / 2)\n",
    "    return pi\n",
    "\n",
    "\n",
    "@jax.jit\n",
    "def jax_sort_marginal (x, w):\n",
    "    \"\"\" sort X and and re-arrange w to correspond to sorted indices \"\"\"\n",
    "    x_w = jnp.stack((x, w)).T\n",
    "    sorted_x, sorted_w = jax.lax.sort_key_val(x, w)\n",
    "    return {\"x\": sorted_x, \"w\": sorted_w}\n",
    "\n",
    "\n",
    "def argsort_marginal (x, w):\n",
    "    \"\"\" sort X and and re-arrange w to correspond to sorted indices \"\"\"\n",
    "    sort_indices = jnp.argsort(x)\n",
    "    return {\"x\": jnp.take(x, sort_indices),\n",
    "            \"w\": jnp.take(w, sort_indices),\n",
    "            \"indices\": sort_indices}\n",
    "\n",
    "\n",
    "# @jax.jit\n",
    "def weighted_corr (X, weights):\n",
    "    \"\"\"\n",
    "    Return weighted correlation matrix\n",
    "    \"\"\"\n",
    "    corr_mat = jnp.cov(X, aweights = weights)\n",
    "    stddevs = jnp.sqrt(jnp.diag(corr_mat))\n",
    "    corr_mat = corr_mat / stddevs[:, None] / stddevs[None, :]\n",
    "    return corr_mat\n",
    "\n",
    "\n",
    "# @jax.jit\n",
    "def marginal_cdf (x, data, weights):\n",
    "    return sum(jnp.where(data < x, x = weights, y=0))\n",
    "\n",
    "\n",
    "# @partial(jax.jit, static_argnums=(3,))\n",
    "def gaussian_copula (key, X, weights, N):\n",
    "    \"\"\"\n",
    "    Estimate and sample from a Gaussian copula as follows: \n",
    "    \n",
    "        - Find Y = (F_1(X_1), ..., F_d(X_d))\n",
    "        - rho_hat = weighted correlation of Y \n",
    "        - Sample Z ~ N(0, rho_hat) N times\n",
    "        - Create U = (phi(Z_1), ..., phi(Z_d))\n",
    "        - Use inverse-CDF of marginals to create samples: (inv-CDF(U_1), ..., inv-CDF(U_d))\n",
    "    \n",
    "    Args:\n",
    "        - key: \n",
    "        - X: \n",
    "        - weights:\n",
    "        - N: Number of samples to generate from the GC\n",
    "    \"\"\"\n",
    "    n, d = X.shape\n",
    "    # estimate correlation matrix: \n",
    "    Y = jax.vmap(\n",
    "        lambda x: \n",
    "        jax.vmap(\n",
    "            marginal_cdf,\n",
    "            in_axes = (0, None, None)\n",
    "        )(x, x, weights),\n",
    "        in_axes = (1))(X)\n",
    "    rho_hat = weighted_corr(Y, weights = weights)\n",
    "\n",
    "    # gaussian copula: \n",
    "    Z = random.multivariate_normal(key=key, mean = np.zeros(d), cov = rho_hat, shape = (N,))\n",
    "    U = jax.scipy.stats.norm.cdf(Z)\n",
    "\n",
    "    sorted_marginals = jax.vmap(\n",
    "        jax_sort_marginal,\n",
    "        in_axes = (1, None)\n",
    "    )(X, weights)\n",
    "    interpolated_weights = jax.vmap(interpolate_weights, in_axes = (0,))(sorted_marginals[\"w\"])\n",
    "    \n",
    "    x_samples = jax.vmap(\n",
    "        lambda x, w, u: jax.vmap(\n",
    "            continuous_cdf,\n",
    "            in_axes= (None, None, 0)\n",
    "        )(x, w, u),\n",
    "        in_axes = (0, 0, 1))(sorted_marginals[\"x\"], interpolated_weights, U)\n",
    "\n",
    "    return x_samples\n",
    "\n",
    "\n",
    "def gaussian_copula2 (key, X, weights, N):\n",
    "    \"\"\"\n",
    "    Estimate and sample from a Gaussian copula as follows: \n",
    "    \n",
    "        - Find Y = (F_1(X_1), ..., F_d(X_d))\n",
    "        - rho_hat = weighted correlation of Y \n",
    "        - Sample Z ~ N(0, rho_hat) N times\n",
    "        - Create U = (phi(Z_1), ..., phi(Z_d))\n",
    "        - Use inverse-CDF of marginals to create samples: (inv-CDF(U_1), ..., inv-CDF(U_d))\n",
    "    \n",
    "    Args:\n",
    "        - key: \n",
    "        - X: \n",
    "        - weights:\n",
    "        - N: Number of samples to generate from the GC\n",
    "    \"\"\"\n",
    "    n, d = X.shape\n",
    "    \n",
    "    # sort marginals: \n",
    "    sorted_marginals = jax.vmap(\n",
    "        argsort_marginal,\n",
    "        in_axes = (1, None)\n",
    "    )(X, weights)\n",
    "\n",
    "    # estimate correlation matrix: \n",
    "    w_cumsum = jnp.cumsum(weights)\n",
    "    Y = jax.vmap(lambda ind: jnp.take(w_cumsum, ind, axis = 0), in_axes = (0, ))(sorted_marginals[\"indices\"])\n",
    "    rho_hat = weighted_corr(Y, weights = weights)\n",
    "\n",
    "    # gaussian copula: \n",
    "    Z = random.multivariate_normal(key=key, mean = np.zeros(d), cov = rho_hat, shape = (N,))\n",
    "    U = jax.scipy.stats.norm.cdf(Z)\n",
    "\n",
    "    interpolated_weights = jax.vmap(interpolate_weights, in_axes = (0,))(sorted_marginals[\"w\"])\n",
    "    x_samples = jax.vmap(\n",
    "        lambda x, w, u: jax.vmap(\n",
    "            continuous_cdf,\n",
    "            in_axes= (None, None, 0)\n",
    "        )(x, w, u),\n",
    "        in_axes = (0, 0, 1))(sorted_marginals[\"x\"], interpolated_weights, U)\n",
    "    return x_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sort_marginal_np (x, w):\n",
    "    \"\"\" sort X and and re-arrange w to correspond to sorted indices \"\"\"\n",
    "    x_w = dict(zip(x, w))\n",
    "    sorted_x_dict = dict(sorted(x_w.items(), key = lambda x: x[0]))\n",
    "    sorted_x = jnp.array(list(sorted_x_dict.keys()))\n",
    "    sorted_w = jnp.array(list(sorted_x_dict.values()))\n",
    "    return sorted_x, sorted_w\n",
    "\n",
    "# generate some data: \n",
    "N = 25\n",
    "rv = norm()\n",
    "x = rv.rvs(size=N)\n",
    "\n",
    "w = rv.pdf(x)\n",
    "w = w / sum(w)\n",
    "\n",
    "sorted_x, sorted_w = sort_marginal_np(x, w)\n",
    "\n",
    "sorted_x_jnp = jnp.array(sorted_x)\n",
    "jnp_sorted_weights = jnp.array(sorted_w)\n",
    "U = random.uniform(random.PRNGKey(0), shape = (100_000,))\n",
    "\n",
    "# TODO: pass U as an array\n",
    "jax_samples = jax.vmap(\n",
    "    continuous_cdf,\n",
    "    in_axes= (None, None, 0)\n",
    ")(sorted_x_jnp, jnp_sorted_weights, U)\n",
    "\n",
    "sns.ecdfplot(x=jax_samples, alpha=0.8, color='firebrick').set(title = 'JAX continuous CDF')\n",
    "sns.ecdfplot(x=x, weights = w);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimizations\n",
    "\n",
    "\n",
    "To find the marginal CDF of X_i, we can map the index of (X_i == x) to the cumulative sum of the weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "_cov = -1\n",
    "mvn = stats.multivariate_normal(mean = [5, 0.4], cov = [[3, _cov], [_cov, 1]])\n",
    "N = 5\n",
    "X = mvn.rvs(N)\n",
    "W = np.ones(N)/N"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sorted:  [[0.2 0.4 0.6 0.8 1. ]\n",
      " [0.2 0.4 0.6 0.8 1. ]]\n",
      "double vmap:  [[0.  0.2 0.4 0.6 0.8]\n",
      " [0.  0.2 0.4 0.6 0.8]]\n"
     ]
    }
   ],
   "source": [
    "sorted_sm = jax.vmap(\n",
    "    jax_sort_marginal,\n",
    "    in_axes=(1, None)\n",
    ")(X, W)\n",
    "\n",
    "print(\"sorted: \", jax.vmap(lambda w: jnp.cumsum(w), in_axes = (0,))(sorted_sm[\"w\"]))\n",
    "\n",
    "Y_jax = jax.vmap(\n",
    "    lambda x, w: \n",
    "    jax.vmap(\n",
    "        marginal_cdf,\n",
    "        in_axes = (0, None, None)\n",
    "    )(x, x, w),\n",
    "    in_axes = (0,0))(sorted_sm[\"x\"], sorted_sm[\"w\"])\n",
    "print(\"double vmap: \", Y_jax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Y:  [[0.8 0.2 0.4 1.  0.6]\n",
      " [0.6 1.  0.4 0.2 0.8]]\n",
      "[[ 1.         -0.70000005]\n",
      " [-0.70000005  1.        ]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DeviceArray([[5.7073274, 2.512596 , 5.7421117, 1.999451 , 5.5758343,\n",
       "              1.4476354, 2.796783 , 5.5887423, 5.0557146, 5.7421117],\n",
       "             [0.1144999, 1.7572486, 0.1144999, 1.7177954, 1.9855561,\n",
       "              2.0399065, 1.4875599, 1.7616724, 1.8672589, 0.1144999]],            dtype=float32)"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sort marginals: \n",
    "sorted_marginals = jax.vmap(\n",
    "    jax_sort_marginal,\n",
    "    in_axes = (1, None)\n",
    ")(X, W)\n",
    "\n",
    "# estimate correlation matrix: \n",
    "w_cumsum = jnp.cumsum(W)\n",
    "Y = jax.vmap(lambda x: jnp.take(w_cumsum, jnp.argsort(x), axis = 0), in_axes = (1, ))(X)\n",
    "\n",
    "rho_hat = weighted_corr(Y, weights = W)\n",
    "print(\"Y: \", Y)\n",
    "print(rho_hat)\n",
    "\n",
    "# gaussian copula: \n",
    "Z = random.multivariate_normal(key=random.PRNGKey(0), mean = np.zeros(rho_hat.shape[0]),\n",
    "                               cov = rho_hat, \n",
    "                               shape = (10,))\n",
    "U = jax.scipy.stats.norm.cdf(Z)\n",
    "\n",
    "interpolated_weights = jax.vmap(interpolate_weights, in_axes = (0,))(sorted_marginals[\"w\"])\n",
    "x_samples = jax.vmap(\n",
    "    lambda x, w, u: jax.vmap(\n",
    "        continuous_cdf,\n",
    "        in_axes= (None, None, 0)\n",
    "    )(x, w, u),\n",
    "    in_axes = (0, 0, 1))(sorted_marginals[\"x\"], interpolated_weights, U)\n",
    "x_samples "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Y:  [[0.8 0.2 0.4 1.  0.6]\n",
      " [0.6 1.  0.4 0.2 0.8]]\n",
      "[[ 1.         -0.70000005]\n",
      " [-0.70000005  1.        ]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DeviceArray([[5.7073274, 2.512596 , 5.7421117, 1.999451 , 5.5758343,\n",
       "              1.4476354, 2.796783 , 5.5887423, 5.0557146, 5.7421117],\n",
       "             [0.1144999, 1.7572486, 0.1144999, 1.7177954, 1.9855561,\n",
       "              2.0399065, 1.4875599, 1.7616724, 1.8672589, 0.1144999]],            dtype=float32)"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sort marginals: \n",
    "sorted_marginals = jax.vmap(\n",
    "    argsort_marginal,\n",
    "    in_axes = (1, None)\n",
    ")(X, W)\n",
    "\n",
    "# estimate correlation matrix: \n",
    "w_cumsum = jnp.cumsum(W)\n",
    "Y = jax.vmap(lambda ind: jnp.take(w_cumsum, ind, axis = 0), in_axes = (0, ))(sorted_marginals[\"indices\"])\n",
    "print(\"Y: \", Y)\n",
    "\n",
    "rho_hat = weighted_corr(Y, weights = W)\n",
    "print(rho_hat)\n",
    "\n",
    "# gaussian copula: \n",
    "Z = random.multivariate_normal(key=random.PRNGKey(0), mean = np.zeros(rho_hat.shape[0]),\n",
    "                               cov = rho_hat, \n",
    "                               shape = (10,))\n",
    "U = jax.scipy.stats.norm.cdf(Z)\n",
    "\n",
    "interpolated_weights = jax.vmap(interpolate_weights, in_axes = (0,))(sorted_marginals[\"w\"])\n",
    "x_samples = jax.vmap(\n",
    "    lambda x, w, u: jax.vmap(\n",
    "        continuous_cdf,\n",
    "        in_axes= (None, None, 0)\n",
    "    )(x, w, u),\n",
    "    in_axes = (0, 0, 1))(sorted_marginals[\"x\"], interpolated_weights, U)\n",
    "x_samples "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gaussian Copula\n",
    "\n",
    "- Find the inverse CDF for each marginal: \n",
    "    - Order each marginal and their corresponding weights: $(X^{(1)}_j, ..., X^{(n)}_j)$, $w_{1j}, ..., w_{nj}$ for $j=1,...,d$\n",
    "- Estimate weighted correlation matrix, $\\rho$\n",
    "- Generate $Z \\sim MVN(0, \\rho)$\n",
    "- Create uniforms using the Gaussian CDF as: $U = (\\Phi(Z_1),..., \\Phi(Z_d))$\n",
    "- Use inverse CDF, $F^{-1}$ (`continuous_cdf`) to sample from ECDF as: $F^{-1}(X_j, w_j, U_j)$, for $j=1,...,d$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "_cov = -1\n",
    "mvn = stats.multivariate_normal(mean = [5, 0.4], cov = [[3, _cov], [_cov, 1]])\n",
    "mvn2 = stats.multivariate_normal(mean = [1, 0.4], cov = [[2, 0], [0, 1]])\n",
    "N = 1000\n",
    "X = mvn.rvs(N)\n",
    "# X = np.random.random(size = (N, 2))\n",
    "W = np.ones(N)/N\n",
    "W = W/sum(W)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DeviceArray([[ 6.8400083 ,  4.083136  ,  9.318392  ,  3.7218294 ,\n",
       "               5.569191  ,  3.1884687 ,  4.2461762 ,  5.8707914 ,\n",
       "               4.855454  ,  9.91684   ],\n",
       "             [-0.98393303,  0.6933958 , -2.3651156 ,  0.5748712 ,\n",
       "               1.6497561 ,  2.1325276 ,  0.28873655,  0.95826834,\n",
       "               1.0993931 , -1.4915819 ]], dtype=float32)"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gaussian_copula(key = random.PRNGKey(0), X = jnp.array(X), weights = jnp.array(W), N=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Shapes must be 1D sequences of concrete values of integer type, got (Traced<ShapedArray(int32[], weak_type=True)>with<DynamicJaxprTrace(level=0/1)>,).\nIf using `jit`, try using `static_argnums` or applying `jit` to smaller subfunctions.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [152], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mgaussian_copula2\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mrandom\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mPRNGKey\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mjnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marray\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweights\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mjnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marray\u001b[49m\u001b[43m(\u001b[49m\u001b[43mW\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mN\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "    \u001b[0;31m[... skipping hidden 14 frame]\u001b[0m\n",
      "Cell \u001b[0;32mIn [149], line 153\u001b[0m, in \u001b[0;36mgaussian_copula2\u001b[0;34m(key, X, weights, N)\u001b[0m\n\u001b[1;32m    150\u001b[0m rho_hat \u001b[38;5;241m=\u001b[39m weighted_corr(Y, weights \u001b[38;5;241m=\u001b[39m weights)\n\u001b[1;32m    152\u001b[0m \u001b[38;5;66;03m# gaussian copula: \u001b[39;00m\n\u001b[0;32m--> 153\u001b[0m Z \u001b[38;5;241m=\u001b[39m \u001b[43mrandom\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmultivariate_normal\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmean\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mzeros\u001b[49m\u001b[43m(\u001b[49m\u001b[43md\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcov\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mrho_hat\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshape\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mN\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    154\u001b[0m U \u001b[38;5;241m=\u001b[39m jax\u001b[38;5;241m.\u001b[39mscipy\u001b[38;5;241m.\u001b[39mstats\u001b[38;5;241m.\u001b[39mnorm\u001b[38;5;241m.\u001b[39mcdf(Z)\n\u001b[1;32m    156\u001b[0m interpolated_weights \u001b[38;5;241m=\u001b[39m jax\u001b[38;5;241m.\u001b[39mvmap(interpolate_weights, in_axes \u001b[38;5;241m=\u001b[39m (\u001b[38;5;241m0\u001b[39m,))(sorted_marginals[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n",
      "File \u001b[0;32m~/opt/miniconda3/envs/pfjax2/lib/python3.9/site-packages/jax/_src/random.py:607\u001b[0m, in \u001b[0;36mmultivariate_normal\u001b[0;34m(key, mean, cov, shape, dtype, method)\u001b[0m\n\u001b[1;32m    605\u001b[0m dtype \u001b[38;5;241m=\u001b[39m dtypes\u001b[38;5;241m.\u001b[39mcanonicalize_dtype(dtype)\n\u001b[1;32m    606\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m shape \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 607\u001b[0m   shape \u001b[38;5;241m=\u001b[39m \u001b[43mcore\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcanonicalize_shape\u001b[49m\u001b[43m(\u001b[49m\u001b[43mshape\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    608\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _multivariate_normal(key, mean, cov, shape, dtype, method)\n",
      "File \u001b[0;32m~/opt/miniconda3/envs/pfjax2/lib/python3.9/site-packages/jax/core.py:1831\u001b[0m, in \u001b[0;36mcanonicalize_shape\u001b[0;34m(shape, context)\u001b[0m\n\u001b[1;32m   1829\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m   1830\u001b[0m   \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[0;32m-> 1831\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m _invalid_shape_error(shape, context)\n",
      "\u001b[0;31mTypeError\u001b[0m: Shapes must be 1D sequences of concrete values of integer type, got (Traced<ShapedArray(int32[], weak_type=True)>with<DynamicJaxprTrace(level=0/1)>,).\nIf using `jit`, try using `static_argnums` or applying `jit` to smaller subfunctions."
     ]
    }
   ],
   "source": [
    "gaussian_copula2(key = random.PRNGKey(0), X = jnp.array(X), weights = jnp.array(W), N=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_samples = gaussian_copula(key = random.PRNGKey(0), X = jnp.array(X), weights = jnp.array(W), N=10)\n",
    "X_samples = pd.DataFrame(np.array(x_samples).T, columns = [\"x0_samples\", \"x1_samples\"])\n",
    "sns.jointplot(x = \"x0_samples\", y = \"x1_samples\", data = X_samples, kind = \"kde\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_samples2 = gaussian_copula2(key = random.PRNGKey(0), X = jnp.array(X), weights = jnp.array(W), N=10)\n",
    "X_samples2 = pd.DataFrame(np.array(x_samples2).T, columns = [\"x0_samples\", \"x1_samples\"])\n",
    "sns.jointplot(x = \"x0_samples\", y = \"x1_samples\", data = X_samples2, kind = \"kde\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_samples = pd.DataFrame(np.array(X), columns = [\"x0\", \"x1\"])\n",
    "sns.jointplot(x = \"x0\", y = \"x1\", data = X_samples, kind = \"kde\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculation 1:  -2.6801817191625315\n",
      "Calculation 2:  -1.260449053076053\n",
      "true:  -0.9247544396787253\n"
     ]
    }
   ],
   "source": [
    "print(\"Calculation 1: \", np.cov(x_samples)[1,0])\n",
    "print(\"Calculation 2: \", np.cov(x_samples2)[1,0])\n",
    "print(\"true: \", np.cov(X.T)[1,0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import os\n",
    "import sys\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import scipy.stats\n",
    "import matplotlib.pyplot as plt\n",
    "import projplot.proj_plot as pjp\n",
    "\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import jax.random as random\n",
    "\n",
    "import pfjax as pf\n",
    "from pfjax import particle_resamplers as resampler\n",
    "from pfjax import models\n",
    "import optax\n",
    "from functools import partial\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# parameter values\n",
    "alpha = 1.0\n",
    "beta = 1.0\n",
    "gamma = 4.0\n",
    "delta = 1.0\n",
    "sigma_h = 0.1\n",
    "sigma_l = 0.1\n",
    "tau_h = 0.25\n",
    "tau_l = 0.25\n",
    "\n",
    "theta = np.array([alpha, beta, gamma, delta, sigma_h, sigma_l, tau_h, tau_l])\n",
    "theta_names = [\"alpha\", \"beta\", \"gamma\", \"delta\",\n",
    "               \"sigma_h\", \"sigma_l\", \"tau_h\", \"tau_l\"]\n",
    "theta_lims = np.array(list(zip(theta - (theta/2), theta + (theta/2))))\n",
    "\n",
    "dt = 0.1\n",
    "n_res = 1\n",
    "n_obs = 100\n",
    "\n",
    "key = random.PRNGKey(0)\n",
    "key, subkey = random.split(key)\n",
    "\n",
    "lotvol_model = models.LotVolModel(dt, n_res) \n",
    "\n",
    "x_init = jnp.block([[jnp.zeros((n_res-1, 2))],\n",
    "                    [jnp.log(jnp.array([5., 3.]))]])\n",
    "\n",
    "y_meas, x_state = pf.simulate(model = lotvol_model, \n",
    "                              n_obs = n_obs, \n",
    "                              x_init = x_init, \n",
    "                              theta = theta, \n",
    "                              key = subkey)\n",
    "y_meas_abs = jnp.abs(y_meas)\n",
    "\n",
    "theta_lims = jnp.array([\n",
    "    [0.8, 1.2],\n",
    "    [0.9, 1.1],\n",
    "    [3.8, 4.2],\n",
    "    [0.95, 1.05],\n",
    "    [0.01, 0.2],\n",
    "    [0.01, 0.2],\n",
    "    [0.2, 0.3],\n",
    "    [0.2, 0.3]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def continuous_cdf (xs, pi, u):\n",
    "    \"\"\"\n",
    "    Return a sample from a continuous approximation of the ECDF of x.\n",
    "\n",
    "    Args: \n",
    "        - xs: Marginals\n",
    "        - pi: interpolated weights of each x. Should be of length: len(xs) + 1\n",
    "        - u: U(0,1)\n",
    "    \n",
    "    Returns: \n",
    "        Sample\n",
    "    \"\"\"\n",
    "    n = len(xs)    \n",
    "\n",
    "    w_cdf = jnp.cumsum(pi)\n",
    "    r = jnp.argmax(w_cdf > u)\n",
    "    u_new = (u - w_cdf[r-1]) / pi[r]\n",
    "    \n",
    "    # select region: \n",
    "    new_x = jax.lax.cond(\n",
    "        r == 0,\n",
    "        lambda _: xs[0],\n",
    "        lambda _: jax.lax.cond(\n",
    "            r == n,\n",
    "            lambda _: xs[-1],\n",
    "            lambda _: (xs[r] - xs[r-1]) * u_new + xs[r-1],\n",
    "            r\n",
    "        ),\n",
    "        r\n",
    "    )\n",
    "    return new_x\n",
    "\n",
    "\n",
    "def interpolate_weights (weights):\n",
    "    \"\"\" Interpolate weights as in Malik&Pitt \"\"\"\n",
    "    n = len(weights) \n",
    "    pi = jnp.zeros(n + 1)\n",
    "    pi = pi.at[0].set(weights[0] / 2)\n",
    "    pi = pi.at[n].set(weights[-1] / 2)\n",
    "    pi = pi.at[1:n].set((weights[:-1] + weights[1:]) / 2)\n",
    "    return pi\n",
    "\n",
    "\n",
    "# def sort_marginal (x, weights):\n",
    "#     r\"\"\" \n",
    "#     Sort X and return corresponding w\n",
    "#     \"\"\"\n",
    "#     sorted_x, sorted_w = jax.lax.sort_key_val(x, weights)\n",
    "#     return {\"x\": sorted_x, \"w\": sorted_w}\n",
    "\n",
    "def argsort_marginal (x, w):\n",
    "    \"\"\" sort (x,w) based on x and return the indices of the sort \"\"\"\n",
    "    sort_indices = jnp.argsort(x)\n",
    "    return {\"x\": jnp.take(x, sort_indices),\n",
    "            \"w\": jnp.take(w, sort_indices),\n",
    "            \"indices\": sort_indices}\n",
    "\n",
    "\n",
    "def weighted_corr (X, weights):\n",
    "    r\"\"\"\n",
    "    Return weighted correlation matrix\n",
    "    \"\"\"\n",
    "    corr_mat = jnp.cov(X, aweights = weights)\n",
    "    stddevs = jnp.sqrt(jnp.diag(corr_mat))\n",
    "    corr_mat = corr_mat / stddevs[:, None] / stddevs[None, :]\n",
    "    return corr_mat\n",
    "\n",
    "\n",
    "def marginal_cdf (x, data, weights):\n",
    "    r\"\"\"\n",
    "    Return quantile of x given data and weights\n",
    "    \"\"\"\n",
    "    return sum(jnp.where(data <= x, x = weights, y=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resample_gaussian_copula(key, x_particles_prev, prob):\n",
    "    r\"\"\"\n",
    "    Particle resampler with Gaussian Copula distribution.\n",
    "\n",
    "    Estimate and sample from a Gaussian copula as follows: \n",
    "        - Find Y = (F_1(X_1), ..., F_d(X_d))\n",
    "        - rho_hat = weighted correlation of Y \n",
    "        - Sample Z ~ N(0, rho_hat) N times\n",
    "        - Create U = (phi(Z_1), ..., phi(Z_d))\n",
    "        - Use inverse-CDF of marginals to create samples: (inv-CDF(U_1), ..., inv-CDF(U_d))\n",
    "\n",
    "    Args: \n",
    "        key: PRNG key\n",
    "        x_particles_prev: An `ndarray` with leading dimension `n_particles` consisting of the particles from the previous time step.\n",
    "        logw: Vector of corresponding `n_particles` unnormalized log-weights.\n",
    "\n",
    "    Returns: \n",
    "        A dictionary with elements:\n",
    "            - `x_particles`: An `ndarray` with leading dimension `n_particles` consisting of the particles from the current time step.  These are sampled with replacement from `x_particles_prev` with probability vector `exp(logw) / sum(exp(logw))`.\n",
    "            - `ancestors`: Vector of `n_particles` integers between 0 and `n_particles-1` giving the index of each element of `x_particles_prev` corresponding to the elements of `x_particles`.\n",
    "\n",
    "    TODO: \n",
    "        - Should be able to use jnp.take() with the `continuous_cdf` block and remove a vmap\n",
    "    \"\"\"\n",
    "    p_shape = x_particles_prev.shape\n",
    "    n_particles = p_shape[0]\n",
    "    x_particles = x_particles_prev.reshape((n_particles, -1))\n",
    "    d = x_particles.shape[-1]\n",
    "#     prob = lwgt_to_prob(logw)\n",
    "    \n",
    "    # sort marginals: \n",
    "    sorted_marginals = jax.vmap(\n",
    "        argsort_marginal,\n",
    "        in_axes = (1, None)\n",
    "    )(x_particles, prob)\n",
    "\n",
    "    # estimate correlation matrix: \n",
    "    w_cumsum = jnp.cumsum(prob)\n",
    "#     Y = jax.vmap(lambda ind: jnp.take(w_cumsum, ind, axis = 0), in_axes = (0, ))(sorted_marginals[\"indices\"])\n",
    "\n",
    "    Y = jax.vmap(\n",
    "        lambda unsorted_x, sorted_x, sorted_index: jax.vmap(\n",
    "            lambda x, w: w[jnp.argmax(sorted_x == x)],\n",
    "            in_axes = (0, None)\n",
    "        )(unsorted_x, jnp.cumsum(prob[sorted_index])),\n",
    "        in_axes = (1, 0, 0,)\n",
    "    )(x_particles, sorted_marginals[\"x\"], sorted_marginals[\"indices\"])\n",
    "    \n",
    "    print(\"sorted_marginals indices shape: \", sorted_marginals[\"indices\"].shape)\n",
    "    print(\"Y shape: \", Y.shape)\n",
    "    print(\"prob shape: \", prob.shape)\n",
    "    rho_hat = weighted_corr(Y, weights = prob)\n",
    "    print(\"rho: \", rho_hat)\n",
    "\n",
    "    # gaussian copula: \n",
    "    Z = random.multivariate_normal(key=key, mean = jnp.zeros(d), cov = rho_hat, shape = (n_particles,))\n",
    "    U = jax.scipy.stats.norm.cdf(Z)\n",
    "\n",
    "    interpolated_weights = jax.vmap(interpolate_weights, in_axes = (0,))(sorted_marginals[\"w\"])\n",
    "    \n",
    "    x_samples = jax.vmap(\n",
    "        lambda x, w, u: jax.vmap(\n",
    "            continuous_cdf,\n",
    "            in_axes= (None, None, 0)\n",
    "        )(x, w, u),\n",
    "        in_axes = (0, 0, 1))(sorted_marginals[\"x\"], interpolated_weights, U)\n",
    "\n",
    "    return {\n",
    "        \"Y\": Y,\n",
    "        \"x_particles\": jnp.reshape(jnp.transpose(x_samples), newshape=p_shape),\n",
    "        \"U\": U,\n",
    "        \"weights\": interpolated_weights\n",
    "    }\n",
    "\n",
    "\n",
    "# # @partial(jax.jit, static_argnums=(3,))\n",
    "def resample_gaussian_copula2(key, x_particles_prev, prob):\n",
    "    r\"\"\"\n",
    "    Particle resampler with Gaussian Copula distribution.\n",
    "\n",
    "    Estimate and sample from a Gaussian copula as follows: \n",
    "        - Find Y = (F_1(X_1), ..., F_d(X_d))\n",
    "        - rho_hat = weighted correlation of Y \n",
    "        - Sample Z ~ N(0, rho_hat) N times\n",
    "        - Create U = (phi(Z_1), ..., phi(Z_d))\n",
    "        - Use inverse-CDF of marginals to create samples: (inv-CDF(U_1), ..., inv-CDF(U_d))\n",
    "\n",
    "    Args: \n",
    "        key: PRNG key\n",
    "        x_particles_prev: An `ndarray` with leading dimension `n_particles` consisting of the particles from the previous time step.\n",
    "        logw: Vector of corresponding `n_particles` unnormalized log-weights.\n",
    "\n",
    "    Returns: \n",
    "        A dictionary with elements:\n",
    "            - `x_particles`: An `ndarray` with leading dimension `n_particles` consisting of the particles from the current time step.  These are sampled with replacement from `x_particles_prev` with probability vector `exp(logw) / sum(exp(logw))`.\n",
    "            - `ancestors`: Vector of `n_particles` integers between 0 and `n_particles-1` giving the index of each element of `x_particles_prev` corresponding to the elements of `x_particles`.\n",
    "    \"\"\"\n",
    "    p_shape = x_particles_prev.shape\n",
    "    n_particles = p_shape[0]\n",
    "    x_particles = x_particles_prev.reshape((n_particles, -1))\n",
    "    d = x_particles.shape[-1]\n",
    "#     prob = lwgt_to_prob(logw)\n",
    "\n",
    "    # estimate correlation matrix: \n",
    "    Y = jax.vmap(\n",
    "        lambda x: \n",
    "        jax.vmap(\n",
    "            marginal_cdf,\n",
    "            in_axes = (0, None, None)\n",
    "        )(x, x, prob),\n",
    "        in_axes = (1))(x_particles)\n",
    "    rho_hat = weighted_corr(Y, weights = prob)\n",
    "    print(\"rho: \", rho_hat)\n",
    "\n",
    "    # gaussian copula: \n",
    "    Z = random.multivariate_normal(key=key, mean = jnp.zeros(d), cov = rho_hat, shape = (n_particles,))\n",
    "    U = jax.scipy.stats.norm.cdf(Z)\n",
    "\n",
    "    sorted_marginals = jax.vmap(\n",
    "        argsort_marginal,\n",
    "        in_axes = (-1, None)\n",
    "    )(x_particles, prob)\n",
    "\n",
    "    interpolated_weights = jax.vmap(interpolate_weights, in_axes = (0,))(sorted_marginals[\"w\"])\n",
    "    x_samples = jax.vmap(\n",
    "        lambda x, w, u: jax.vmap(\n",
    "            continuous_cdf,\n",
    "            in_axes= (None, None, 0)\n",
    "        )(x, w, u),\n",
    "        in_axes = (0, 0, 1))(sorted_marginals[\"x\"], interpolated_weights, U)\n",
    "\n",
    "    return {\n",
    "        \"Y\": Y,\n",
    "        \"x_particles\": jnp.reshape(jnp.transpose(x_samples), newshape=p_shape),\n",
    "        \"U\": U,\n",
    "        \"weights\": interpolated_weights\n",
    "    }\n",
    "\n",
    "def lotvol_neg_loglik(theta, model = lotvol_model, resampler = resampler.resample_mvn, n_particles=25):\n",
    "    \"\"\"\n",
    "    Negative log-likelihood for lotka volterra model (lotvol_model)\n",
    "    \"\"\"\n",
    "    temp = pf.particle_filter(\n",
    "        theta=theta, \n",
    "        model=model, \n",
    "        y_meas=y_meas, \n",
    "        n_particles=n_particles, \n",
    "        key=key,\n",
    "        resampler = resampler)\n",
    "    return -temp[\"loglik\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "68.79495\n",
      "sorted_marginals indices shape:  (2, 25)\n",
      "Y shape:  (2, 25)\n",
      "prob shape:  (25,)\n",
      "rho:  Traced<ShapedArray(float32[2,2])>with<DynamicJaxprTrace(level=1/0)>\n",
      "weights:  Traced<ShapedArray(float32[2,26])>with<DynamicJaxprTrace(level=1/0)>\n",
      "104.93817\n",
      "rho:  Traced<ShapedArray(float32[2,2])>with<DynamicJaxprTrace(level=1/0)>\n",
      "weights:  Traced<ShapedArray(float32[2,26])>with<DynamicJaxprTrace(level=1/0)>\n",
      "73.6201\n"
     ]
    }
   ],
   "source": [
    "print(lotvol_neg_loglik(theta))\n",
    "\n",
    "print(lotvol_neg_loglik(theta, resampler = resampler.resample_gaussian_copula))\n",
    "\n",
    "print(lotvol_neg_loglik(theta, resampler = resample_gaussian_copula2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "particles = np.random.multivariate_normal(size=(5, ), mean = [0, 5], cov=np.eye(2))\n",
    "weights = jnp.array([0.01, 0.19, 0.1, 0.2, 0.5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3.14327517 4.89444051 5.53871311 4.00812407 4.69400143]\n",
      "[0 3 4 1 2]\n"
     ]
    }
   ],
   "source": [
    "print(particles[:,1])\n",
    "print(jnp.argsort(particles[:,1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.13911313 -1.29461864 -1.14398309  0.65659553  0.25110117]\n",
      "[1 2 0 4 3]\n",
      "[-1.2946186433478553, -1.1439830896908831, 0.13911312538291098, 0.25110117301363094, 0.6565955314959282]\n",
      "[-1.29461864 -1.14398309  0.13911313  0.25110117  0.65659553]\n"
     ]
    }
   ],
   "source": [
    "print(particles[:,0])\n",
    "print(jnp.argsort(particles[:,0]))\n",
    "print(sorted(particles[:,0]))\n",
    "print(particles[:,0][jnp.argsort(particles[:,0])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DeviceArray(0.3, dtype=float32)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(jnp.where(particles[:,0] <= 0.13911313, x = weights, y=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DeviceArray(0.3, dtype=float32)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jnp.take(jnp.cumsum(weights), jnp.where(particles[:,0][jnp.argsort(particles[:,0])] == particles[0,0])[0][0])\n",
    "# jnp.where(particles[:,0][jnp.argsort(particles[:,0])] == particles[0,0])[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rho:  [[ 1.0000001  -0.75061756]\n",
      " [-0.75061756  1.0000001 ]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DeviceArray([[0.3       , 0.19      , 0.29      , 1.        , 0.8       ],\n",
       "             [0.01      , 0.9       , 1.        , 0.21000001, 0.71000004]],            dtype=float32)"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c2 = resample_gaussian_copula2(key, particles, weights)\n",
    "\n",
    "c2[\"Y\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sorted_marginals indices shape:  (2, 5)\n",
      "Y shape:  (2, 5)\n",
      "prob shape:  (5,)\n",
      "rho:  [[ 1.         -0.75061756]\n",
      " [-0.7506176   1.0000001 ]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DeviceArray([[0.29999998, 0.19      , 0.29      , 0.99999994, 0.79999995],\n",
       "             [0.01      , 0.9       , 1.        , 0.21000001, 0.71000004]],            dtype=float32)"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c1 = resample_gaussian_copula(key, particles, weights)\n",
    "c1[\"Y\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deprecated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def jax_cont_resample (weights, xs, key):\n",
    "    \"\"\"\n",
    "    Change `seed` to `key`\n",
    "    \"\"\"\n",
    "    n = len(weights)\n",
    "    u_new = jnp.zeros(n)\n",
    "    u0 = random.uniform(key)\n",
    "    u = (u0 + np.arange(n)) / n\n",
    "    u = jnp.array([0.14303787, 0.34303787, 0.54303787, 0.74303787, 0.94303787])\n",
    "    \n",
    "    pi = np.zeros(n + 1)\n",
    "    pi[0] = weights[0] / 2\n",
    "    pi[n] = weights[-1] / 2\n",
    "    pi[1:n] = (weights[:-1] + weights[1:]) / 2\n",
    "    \n",
    "    def region_mid (k, val):\n",
    "        xs = val[\"x\"]\n",
    "        r = val[\"r\"]\n",
    "        u_new = val[\"u_new\"]\n",
    "        return (xs[r[k]] - xs[r[k] - 1]) * u_new[k] + xs[r[k] - 1]\n",
    "    \n",
    "    def while_loop_func (val):\n",
    "        u_j = val[\"u\"][val[\"j\"]]\n",
    "        pi_i = val[\"pi\"][val[\"i\"]]\n",
    "        \n",
    "        val[\"r\"] = val[\"r\"].at[val[\"j\"]].set(val[\"i\"])\n",
    "        val[\"u_new\"] = val[\"u_new\"].at[val[\"j\"]].set((u_j - (val[\"s\"] - pi_i)) / pi_i)\n",
    "        \n",
    "        # select region: \n",
    "        new_x = jax.lax.cond(\n",
    "            val[\"r\"][val[\"j\"]] == 0,\n",
    "            lambda _: val[\"x\"][0],\n",
    "            lambda _: jax.lax.cond(\n",
    "                val[\"r\"][val[\"j\"]] == n,\n",
    "                lambda _: val[\"x\"][-1],\n",
    "                lambda _: region_mid(val[\"j\"], val),\n",
    "                val\n",
    "            ),\n",
    "            val\n",
    "        )\n",
    "        val[\"x_new\"] = val[\"x_new\"].at[val[\"j\"]].set(new_x)\n",
    "        val[\"j\"] += 1\n",
    "        return val \n",
    "\n",
    "    def while_cond (val):\n",
    "        return jnp.logical_and(val[\"j\"] <= n, val[\"u\"][val[\"j\"]] <= val[\"s\"])\n",
    "    \n",
    "    def for_loop_func (i, val):\n",
    "        val[\"s\"] += val[\"pi\"][i]\n",
    "        val[\"i\"] = i\n",
    "        val = jax.lax.while_loop(while_cond, while_loop_func, val)\n",
    "        return val\n",
    " \n",
    "    init_val = {\n",
    "        \"j\": 0,\n",
    "        \"r\": jnp.zeros(n, int),\n",
    "        \"s\": 0,\n",
    "        \"i\": 0,\n",
    "        \"u\": u,\n",
    "        \"u_new\": jnp.zeros(n),\n",
    "        \"x\": xs,\n",
    "        \"x_new\": jnp.zeros(n),\n",
    "        \"pi\": pi}\n",
    "    \n",
    "    val = jax.lax.fori_loop(0, n, for_loop_func, init_val)\n",
    "\n",
    "    # select region: \n",
    "    new_x = jax.lax.cond(\n",
    "        val[\"r\"][val[\"j\"]] == 0,\n",
    "        lambda _: val[\"x\"][0],\n",
    "        lambda _: jax.lax.cond(\n",
    "            val[\"r\"][val[\"j\"]] == n,\n",
    "            lambda _: val[\"x\"][-1],\n",
    "            lambda _: region_mid(val[\"j\"], val),\n",
    "            val\n",
    "        ),\n",
    "        val\n",
    "    )\n",
    "    val[\"x_new\"] = val[\"x_new\"].at[val[\"j\"]].set(new_x)\n",
    "    \n",
    "    return val[\"x_new\"]\n",
    "\n",
    "def continuous_stratified_resample(weights, xs):\n",
    "    \"\"\"\n",
    "    Args: \n",
    "        - weights: normalized weights with indices corresponding to xs. This is represented by \\pi in the paper\n",
    "        - xs: samples sorted in ascending order. Represented by x^{(k)} in the paper. \n",
    "\n",
    "    \"\"\"\n",
    "    n = len(weights)\n",
    "    u0 = np.random.uniform(size=1)\n",
    "    u = (u0 + np.arange(n)) / n\n",
    "    u = np.array([0.14303787, 0.34303787, 0.54303787, 0.74303787, 0.94303787])\n",
    "#     print(u)\n",
    "    \n",
    "    # A.1: general form of continuous distribution\n",
    "    pi = np.zeros(n + 1)\n",
    "    pi[0] = weights[0] / 2\n",
    "    pi[n] = weights[-1] / 2\n",
    "    pi[1:n] = (weights[:-1] + weights[1:]) / 2\n",
    "\n",
    "    # A.3\n",
    "    r = np.zeros(n)\n",
    "    u_new = np.zeros(n)\n",
    "    s = 0\n",
    "    j = 1\n",
    "\n",
    "    for i in range(n + 1):\n",
    "        s = s + pi[i]\n",
    "        while(j <= n and u[j - 1] <= s):\n",
    "            r[j - 1] = i\n",
    "            u_new[j - 1] = (u[j - 1] - (s - pi[i])) / pi[i]\n",
    "            j = j + 1\n",
    "\n",
    "    r = r.astype(int)\n",
    "\n",
    "    x_new = np.zeros(n)\n",
    "    for k in range(n):\n",
    "        if r[k] == 0:\n",
    "            x_new[k] = xs[0]\n",
    "        elif r[k] == n:\n",
    "            x_new[k] = xs[-1]\n",
    "        else:\n",
    "            x_new[k] = (xs[r[k]] - xs[r[k] - 1]) * u_new[k] + xs[r[k] - 1]\n",
    "    return x_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 25\n",
    "rv = norm()\n",
    "x = rv.rvs(size=N)\n",
    "print(x)\n",
    "\n",
    "w = rv.pdf(x)\n",
    "w = w / sum(w)\n",
    "print(w)\n",
    "\n",
    "x_dict = dict(zip(x, w))\n",
    "print(x_dict.keys())\n",
    "\n",
    "sorted_x_dict = dict(sorted(x_dict.items(), key = lambda x: x[0]))\n",
    "sorted_x = np.array(list(sorted_x_dict.keys()))\n",
    "sorted_weights = np.array(list(sorted_x_dict.values()))\n",
    "sorted_x_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Numpy version (fixed U): \", continuous_stratified_resample(sorted_weights, sorted_x))\n",
    "\n",
    "print(\"JAX version (fixed U): \", jax_cont_resample(jnp.array(sorted_weights), \n",
    "                                                   jnp.array(sorted_x), \n",
    "                                                   key = random.PRNGKey(0)))\n",
    "\n",
    "\n",
    "x_new_samples = [continuous_stratified_resample(sorted_weights, sorted_x) for i in range(200)]\n",
    "x_new_samples = np.array(x_new_samples).flatten()\n",
    "\n",
    "sns.ecdfplot(x=x_new_samples, alpha=0.8, color='firebrick').set(title = 'numpy continuous CDF')\n",
    "sns.ecdfplot(x=x, weights = w);\n",
    "\n",
    "\n",
    "keys = jax.random.split(random.PRNGKey(0), 200)\n",
    "jax_x_new_samples = [jax_cont_resample(sorted_weights, sorted_x, key = keys[i]) for i in range(200)]\n",
    "jax_x_new_samples = np.array(jax_x_new_samples).flatten()\n",
    "\n",
    "sns.ecdfplot(x=jax_x_new_samples, alpha=0.8, color='firebrick').set(title = 'JAX continuous CDF')\n",
    "sns.ecdfplot(x=x, weights = w);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## TEST: check weighted correlation matrix \n",
    "\n",
    "rho_hat = np.cov([u0, u1], aweights = W)\n",
    "_vars = np.diag(np.cov([u0, u1], aweights = W))\n",
    "rho_hat[0, 1] = rho_hat[0, 1] / np.sqrt(_vars[0] * _vars[1])\n",
    "rho_hat[1, 0] = rho_hat[0, 1]\n",
    "rho_hat[0,0] = 1\n",
    "rho_hat[1,1] = 1\n",
    "print(rho_hat)\n",
    "\n",
    "rho_hat = np.cov([u0, u1], aweights = W)\n",
    "stddevs = np.sqrt(np.diag(rho_hat))\n",
    "print(rho_hat / stddevs[:, None] / stddevs[None, :])\n",
    "\n",
    "\n",
    "# TEST: check ECDF\n",
    "x0_ecfd = lambda x: sum(W[X[:, 0] < x])\n",
    "x1_ecfd = lambda x: sum(W[X[:, 1] < x])\n",
    "\n",
    "u0 = list(map(x0_ecfd, X[:,  0]))\n",
    "u1 = list(map(x1_ecfd, X[:,  1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# estimate correlation matrix: \n",
    "Y = jax.vmap(\n",
    "    lambda x: \n",
    "    jax.vmap(\n",
    "        marginal_cdf,\n",
    "        in_axes = (0, None, None)\n",
    "    )(x, x, jnp.array(W)),\n",
    "    in_axes = (1))(X)\n",
    "rho_hat = weighted_corr(Y, weights = W)\n",
    "\n",
    "Z = np.random.multivariate_normal(mean = np.zeros(rho_hat.shape[0]), cov = rho_hat, size = 20_000)\n",
    "\n",
    "# gaussian copula: \n",
    "std_normal = norm()\n",
    "U = std_normal.cdf(Z)\n",
    "\n",
    "sorted_marginals = jax.vmap(\n",
    "    jax_sort_marginal,\n",
    "    in_axes = (1, None)\n",
    ")(jnp.array(X), jnp.array(W))\n",
    "\n",
    "x_samples = jax.vmap(\n",
    "    lambda x, w, u: jax.vmap(\n",
    "        continuous_cdf,\n",
    "        in_axes= (None, None, 0)\n",
    "    )(x, w, u),\n",
    "    in_axes = (0, 0, 1))(sorted_marginals[\"x\"], sorted_marginals[\"w\"], U)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# # estimate CDF for each margin: \n",
    "\n",
    "# # X0: \n",
    "# x0 = X[:, 0]\n",
    "# w0 = norm(loc = np.mean(x0), scale = np.std(x0)).pdf(x0)\n",
    "# w0 = w0 / sum(w0) # normalized weights: \n",
    "\n",
    "# # sort x and w:\n",
    "# x0_w0 = dict(zip(x0, w0))\n",
    "# sorted_x0_dict = dict(sorted(x0_w0.items(), key = lambda x: x[0]))\n",
    "# sorted_x0 = jnp.array(list(sorted_x0_dict.keys()))\n",
    "# sorted_w0 = jnp.array(list(sorted_x0_dict.values()))\n",
    "\n",
    "# U = random.uniform(random.PRNGKey(0), shape = (10_000,))\n",
    "\n",
    "# jax_samples = jax.vmap(\n",
    "#     continuous_cdf,\n",
    "#     in_axes= (None, None, 0)\n",
    "# )(sorted_x0, sorted_w0, U)\n",
    "\n",
    "# sns.ecdfplot(x=jax_samples, alpha=0.8, color='firebrick').set(title = 'JAX continuous CDF');\n",
    "# sns.ecdfplot(x=x0, weights = w0, alpha=0.8);\n",
    "\n",
    "\n",
    "# # X1: \n",
    "# x1 = X[:, 1]\n",
    "# w1 = norm(loc = np.mean(x1), scale = np.std(x1)).pdf(x1)\n",
    "# w1 = w1 / sum(w1) # normalized weights: \n",
    "\n",
    "# # sort x and w:\n",
    "# x1_w1 = dict(zip(x1, w1))\n",
    "# sorted_x1_dict = dict(sorted(x1_w1.items(), key = lambda x: x[0]))\n",
    "# sorted_x1 = jnp.array(list(sorted_x1_dict.keys()))\n",
    "# sorted_w1 = jnp.array(list(sorted_x1_dict.values()))\n",
    "\n",
    "# U = random.uniform(random.PRNGKey(0), shape = (10_000,))\n",
    "\n",
    "# jax_samples = jax.vmap(\n",
    "#     continuous_cdf,\n",
    "#     in_axes= (None, None, 0)\n",
    "# )(sorted_x1, sorted_w1, U)\n",
    "\n",
    "# fig, ax = plt.subplots(nrows=1, ncols=1, figsize=(10, 10), sharey = True)\n",
    "# sns.ecdfplot(x=jax_samples, alpha=0.8, color='firebrick', ax = ax).set(title = 'JAX continuous CDF');\n",
    "# sns.ecdfplot(x=x1, weights = w1, alpha=0.4, ax = ax);"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
