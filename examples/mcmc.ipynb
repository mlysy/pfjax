{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "85d2a8b3",
   "metadata": {},
   "source": [
    "# MCMC in PFJAX\n",
    "\n",
    "**Martin Lysy, University of Waterloo** \n",
    "\n",
    "**January 27, 2022**\n",
    "\n",
    "## Overview\n",
    "\n",
    "PFJAX provides the following tools for MCMC sampling from the full posterior distribution $p(\\xx_{0:T}, \\tth \\mid \\yy_{0:T})$:\n",
    "\n",
    "- `pf.particle_filter()` and `pf.particle_smooth()`: Sample from $p(\\xx_{0:T} \\mid \\tth, \\yy_{0:T})$ using a particle filter.\n",
    "\n",
    "- `mcmc.param_mwg_update()` and `mcmc.mwg_adapt()`: Sample from $p(\\tth \\mid \\xx_{0:T}, \\yy_{0:T})$ using an adaptive Metropolis-within-Gibbs (MWG) sampler. \n",
    "\n",
    "## Partially Jitted Gibbs Sampler\n",
    "\n",
    "In this case, the components of the Gibbs sampler are jitted but not the full sampler.  Jitting the full sampler (i.e. using `lax.scan()`) takes a bit more effort.  It would be interesting to compare the timings to see how much benefit this has."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6dd406cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import jax.scipy as jsp\n",
    "import jax.random as random\n",
    "import numpy as np\n",
    "import pfjax as pf\n",
    "import pfjax.mcmc as mcmc\n",
    "from functools import partial\n",
    "\n",
    "# jit the components of the pg sampler\n",
    "\n",
    "\n",
    "@partial(jax.jit, static_argnums=(0, 4))\n",
    "def state_update(model, key, y_meas, theta, n_particles):\n",
    "    \"\"\"\n",
    "    Update the state variables.\n",
    "\n",
    "    **FIXME:** Full docstring in same style as rest of pfjax.\n",
    "    \"\"\"\n",
    "    key, subkey = random.split(key)\n",
    "    pf_out = pf.particle_filter(model, subkey, y_meas, theta, n_particles)\n",
    "    return pf.particle_smooth(model, key,\n",
    "                              logw=pf_out[\"lowg\"][y_meas.shape[0]-1],\n",
    "                              x_particles=pf_out[\"x_particles\"],\n",
    "                              ancestors=pf_out[\"ancestors\"])\n",
    "\n",
    "def param_update(model, prior, key, theta, x_state, y_meas, rw_adapt, n_accept, n_iter):\n",
    "    \"\"\"\n",
    "    Update the parameters and the MWG standard deviations.\n",
    "    \"\"\"\n",
    "    theta, accept = mcmc.param_mwg_update(model, prior, subkeys[1], theta, x_state, y_meas, rw_adapt)\n",
    "    n_accept = n_accept + accept\n",
    "    accept_rate = (1.0 * n_accept) / n_iter\n",
    "    rw_adapt = mcmc.mwg_adapt(rw_adapt, accept_rate, n_iter)\n",
    "    return theta, rw_adapt, n_accept\n",
    "\n",
    "param_update = jax.jit(mcmc.param_mwg_update, static_argnums=(0, 1))\n",
    "\n",
    "\n",
    "def particle_gibbs_for(model, prior, key, n_iter, y_meas, theta_init, n_particles, rw_sd):\n",
    "    \"\"\"\n",
    "    Sample from the joint distribution of `p(x_{0:T}, theta | y_{0:T})` using a Particle Gibbs sampler.\n",
    "    \n",
    "    Args:\n",
    "        model: Object specifying the state-space model.\n",
    "        prior: Object specifying the parameter prior.\n",
    "        key: PRNG key.\n",
    "        n_iter: Number of MCMC iterations.\n",
    "        y_meas: The sequence of `n_obs` measurement variables `y_meas = (y_0, ..., y_T)`, where `T = n_obs-1`.\n",
    "        theta_init: A vector of `n_params` parameter values to initialize the sampler.\n",
    "        n_particles: Number of particles for the particle filter.\n",
    "        rw_sd: Vector of `n_params` initial standard deviations for the adaptive MWG proposal.\n",
    "\n",
    "    Returns:\n",
    "        A dictionary with elements:\n",
    "        - x_state: MCMC output for the state variables, with leading dimension `n_iter`.\n",
    "        - theta: MCMC output for the parameters, with leading dimension `n_iter`.\n",
    "        - accept_rate: Vector of `n_params` acceptance rates.  These should be close to 0.44.\n",
    "    \"\"\"\n",
    "    # initialize the sampler\n",
    "    x_state_out = jnp.zeros((n_iter,) + x_state_init.shape)\n",
    "    n_params = theta.size\n",
    "    theta_order = jnp.arange(n_params)\n",
    "    theta_out = jnp.zeros((n_iter, n_params))\n",
    "    theta = theta_init\n",
    "    rw_adapt = rw_sd\n",
    "    n_accept = jnp.zeros(theta_init.shape)\n",
    "    # run the sampler\n",
    "    for i in range(n_iter):\n",
    "        # perform updates\n",
    "        key, *subkeys = random.split(key, num=3)\n",
    "        x_state = state_update(model, subkeys[0], y_meas, theta, n_particles)\n",
    "        theta, rw_adapt, n_accept = param_update(model, prior, subkeys[1], theta, x_state, y_meas, \n",
    "                                                 rw_adapt, n_accept, i)\n",
    "        # store\n",
    "        theta_out = theta_out.at[i].set(theta)\n",
    "        x_state_out = x_state_out.at[i].set(x_state)\n",
    "    return {\"theta\": theta_out, \"x_state\": x_state_out, \"accept_rate\": (1.0 * n_accept)/n_iter}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcf4b9a9",
   "metadata": {},
   "source": [
    "## Tests\n",
    "\n",
    "- [ ] Check that the code above runs without errors.\n",
    "\n",
    "- [ ] Check MCMC posteriors for simple models (e.g., `BMModel`, `LotVolModel`) against output from a different MCMC sampler, e.g., **Turing.jl**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b03531f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DeviceArray([9, 8, 7, 6, 5, 4, 3, 2, 1, 0], dtype=int64)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jnp.flip(jnp.arange(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a0830e0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": true,
   "report_style_numbering": false,
   "user_envs_cfg": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
