{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# StoichModel Class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Michelle Ko & Martin Lysy, University of Waterloo**\n",
    "\n",
    "**June 29th, 2022**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`StoichModel()` is a class for stoichiometry models casted into SDEs. This class takes two matrices: In-Matrix and Out-Matrix, representing information about the reactants and products, respectively (hence in and out), of the reactions in the dynamic system. The columns corresponds to the reactions and the rows determine the species type. The Stoichiometry Matrix $S$, given by the net effect `Out-Matrix - In-Matrix`, is instrumental to calculating the drift and diffusion of the SDEs, along with the reaction propensity function $h(X, \\theta)$.\n",
    "\n",
    "In cases where $S$ is rank-deficient, the diffusion matrix $S^\\mathsf{T} \\mathrm{diag}(h(X,\\theta)) S$ can no longer be positive-definite, and sampling trajectory from the multivariate normal becomes impossible. In terms of the stoichiometry model, this implies that population of one or more species can be completely explained by that of other species. The procedure that identify, remove, and restore such dependancies, outlined in Ingalls & Bembenek (2014), is implemented in `StoichModel()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/michelleko/anaconda3/lib/python3.7/site-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
      "  import pandas.util.testing as tm\n"
     ]
    }
   ],
   "source": [
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import jax.scipy as jsp\n",
    "from jax import random\n",
    "import pfjax as pf\n",
    "import pfjax.mcmc as mcmc\n",
    "from pfjax import sde as sde\n",
    "from functools import partial\n",
    "\n",
    "import pandas as pd\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class StoichModel(sde.SDEModel):\n",
    "\n",
    "    def __init__(self, dt, n_res, InMatrix_Full, OutMatrix_Full, mask=None, epsilon=1e-6, bootstrap=True):\n",
    "\n",
    "        super().__init__(dt, n_res, diff_diag=False) # Inherits SDEModel class\n",
    "        self._bootstrap = bootstrap\n",
    "        \n",
    "        # Full stoichiometry matrix\n",
    "        self._InMatrix_Full = InMatrix_Full\n",
    "        self._OutMatrix_Full = OutMatrix_Full\n",
    "        self._StoichMatrix_Full =  self._OutMatrix_Full - self._InMatrix_Full\n",
    "        self._n_X_full, self._n_Rxn_full = self._StoichMatrix_Full.shape\n",
    "        \n",
    "        # Linearly independent stoichiometry matrix\n",
    "        q,r = jnp.linalg.qr(jnp.transpose(self._StoichMatrix_Full))\n",
    "        self._mask = jnp.array(jnp.abs(jnp.diag(r))>=epsilon) if mask is None else mask\n",
    "        \n",
    "        # Row-reduced stoichiometry matrix\n",
    "        self._InMatrix = self._InMatrix_Full[self._mask,:]\n",
    "        self._OutMatrix = self._OutMatrix_Full[self._mask,:]\n",
    "        self._StoichMatrix = self._StoichMatrix_Full[self._mask,:]\n",
    "        self._n_X, self._n_Rxn = self._StoichMatrix.shape\n",
    "        \n",
    "        self._n_state = (self._n_res, self._n_X)\n",
    "        \n",
    "        # The link matrix to restore dependent species\n",
    "        self._L = jnp.matmul(self._StoichMatrix_Full, jnp.linalg.pinv(self._StoichMatrix))\n",
    "        mask_matrix = jnp.transpose(jnp.broadcast_to(self._mask, (self._n_X, self._n_X_full))) # mask broadcasted to matrix\n",
    "        self._L0 = jnp.where(jnp.invert(mask_matrix), self._L ,jnp.zeros((self._n_X_full,self._n_X))) \n",
    "        \n",
    "    def _Hazard(self, x, param):\n",
    "        \n",
    "        # Propensity of i-th reaction determined by reaction type\n",
    "        def h(x, param_i, i):\n",
    "\n",
    "            Rxn = self._InMatrix_Full[:,i]\n",
    "\n",
    "            n_mols = sum(Rxn)\n",
    "            n_type = jnp.count_nonzero(Rxn)\n",
    "            index = jnp.nonzero(jnp.array(Rxn),size=2)\n",
    "\n",
    "            if n_mols == 0:\n",
    "                ans = param_i\n",
    "            elif n_mols == 1:\n",
    "                ans = param_i * x[index[0][0]]\n",
    "            elif n_mols == 2 and n_type == 1:\n",
    "                ans = param_i * x[index[0][0]] * (x[index[0][0]] - 1) / 2\n",
    "            elif n_mols == 2 and n_type == 2:\n",
    "                ans = param_i * jnp.prod(x[index[0]])\n",
    "            else:\n",
    "                print('Not supported reaction')\n",
    "                # Throw some error\n",
    "            return ans\n",
    "        \n",
    "        Hazard = jnp.array([h(x, param[i], i) for i in range(self._n_Rxn)])\n",
    "        \n",
    "        return Hazard\n",
    "    \n",
    "    # Restore population of dependent species, given current (independent) and initial (full) population\n",
    "    def _x_full(self, x, x_init):\n",
    "        \n",
    "        T_tilde = jnp.where(jnp.invert(self._mask), x_init, jnp.zeros(self._n_X_full)) - self._L0 @ x_init[self._mask]\n",
    "        x_full = self._L @ x + T_tilde\n",
    "        \n",
    "        return x_full\n",
    "    \n",
    "    # Drift on the regular scale\n",
    "    def _drift(self, x, theta):\n",
    "        x_full = self._x_full(x, theta[(self._n_Rxn + self._n_X):])\n",
    "        Hazard = self._Hazard(x_full, theta[:self._n_Rxn])\n",
    "        mu = self._StoichMatrix @ Hazard\n",
    "        \n",
    "        return mu\n",
    "    \n",
    "    # Diffusion on the regular scale\n",
    "    def _diff(self, x, theta):\n",
    "        x_full = self._x_full(x, theta[(self._n_Rxn + self._n_X):])\n",
    "        Hazard = self._Hazard(x_full, theta[:self._n_Rxn])\n",
    "        Sigma = self._StoichMatrix @ jnp.diag(Hazard) @ jnp.transpose(self._StoichMatrix)\n",
    "\n",
    "        return Sigma\n",
    "    \n",
    "    # Drift on the log scale\n",
    "    def drift(self, x, theta):\n",
    "        x = jnp.exp(x)\n",
    "        mu = self._drift(x, theta)\n",
    "        Sigma = self._diff(x, theta)\n",
    "\n",
    "        f_p = 1/x\n",
    "        f_pp = -1/x/x\n",
    "\n",
    "        mu_trans = f_p * mu + 0.5 * f_pp * jnp.diag(Sigma)\n",
    "        return mu_trans\n",
    "    \n",
    "    # Diffusion on the log scale\n",
    "    def diff(self, x, theta):\n",
    "        x = jnp.exp(x)\n",
    "        Sigma = self._diff(x, theta)\n",
    "\n",
    "        f_p = 1/x\n",
    "        Sigma_trans = jnp.outer(f_p, f_p) * Sigma\n",
    "\n",
    "        return Sigma_trans\n",
    "    \n",
    "    def meas_lpdf(self, y_curr, x_curr, theta):\n",
    "        \"\"\"\n",
    "        Log-density of `p(y_curr | x_curr, theta)`.\n",
    "        Args:\n",
    "            y_curr: Measurement variable at current time `t`.\n",
    "            x_curr: State variable at current time `t`.\n",
    "            theta: Parameter value.\n",
    "        Returns\n",
    "            The log-density of `p(y_curr | x_curr, theta)`.\n",
    "        \"\"\"\n",
    "        tau = theta[self._n_Rxn:(self._n_Rxn+self._n_X)]\n",
    "        return jnp.sum(\n",
    "            jsp.stats.norm.logpdf(y_curr, loc=jnp.exp(x_curr[-1]), scale=tau)\n",
    "        )\n",
    "        \n",
    "    def meas_sample(self, key, x_curr, theta):\n",
    "        \"\"\"\n",
    "        Sample from `p(y_curr | x_curr, theta)`.\n",
    "        Args:\n",
    "            key: PRNG key.\n",
    "            x_curr: State variable at current time `t`.\n",
    "            theta: Parameter value.\n",
    "        Returns:\n",
    "            Sample of the measurement variable at current time `t`: `y_curr ~ p(y_curr | x_curr, theta)`.\n",
    "        \"\"\"\n",
    "        tau = theta[self._n_Rxn:(self._n_Rxn+self._n_X)]\n",
    "        return jnp.exp(x_curr[-1]) + tau * random.normal(key, (self._n_state[1],))\n",
    "    \n",
    "    def pf_init(self, key, y_init, theta):\n",
    "        \"\"\"\n",
    "        Particle filter calculation for `x_init`.\n",
    "        Samples from an importance sampling proposal distribution\n",
    "        ```\n",
    "        x_init ~ q(x_init) = q(x_init | y_init, theta)\n",
    "        ```\n",
    "        and calculates the log weight\n",
    "        ```\n",
    "        logw = log p(y_init | x_init, theta) + log p(x_init | theta) - log q(x_init)\n",
    "        ```\n",
    "        **FIXME:** Explain what the proposal is and why it gives `logw = 0`.\n",
    "        In fact, if you think about it hard enough then it's not actually a perfect proposal...\n",
    "        Args:\n",
    "            y_init: Measurement variable at initial time `t = 0`.\n",
    "            theta: Parameter value.\n",
    "            key: PRNG key.\n",
    "        Returns:\n",
    "            - x_init: A sample from the proposal distribution for `x_init`.\n",
    "            - logw: The log-weight of `x_init`.\n",
    "        \"\"\"\n",
    "        tau = theta[self._n_Rxn:(self._n_Rxn+self._n_X)]\n",
    "\n",
    "        key, subkey = random.split(key)\n",
    "        x_init = jnp.log(y_init + tau * random.truncated_normal(\n",
    "            subkey,\n",
    "            lower=-y_init/tau,\n",
    "            upper=jnp.inf,\n",
    "            shape=(self._n_state[1],)\n",
    "        ))\n",
    "        logw = jnp.sum(jsp.stats.norm.logcdf(y_init/tau))\n",
    "        \n",
    "        return \\\n",
    "            jnp.append(jnp.zeros((self._n_res-1,) + x_init.shape),\n",
    "                       jnp.expand_dims(x_init, axis=0), axis=0), \\\n",
    "            logw\n",
    "    \n",
    "    def pf_step(self, key, x_prev, y_curr, theta):\n",
    "        \"\"\"\n",
    "        Choose between bootstrap filter and bridge proposal.\n",
    "        Args:\n",
    "            x_prev: State variable at previous time `t-1`.\n",
    "            y_curr: Measurement variable at current time `t`.\n",
    "            theta: Parameter value.\n",
    "            key: PRNG key.\n",
    "        Returns:\n",
    "            - x_curr: Sample of the state variable at current time `t`: `x_curr ~ q(x_curr)`.\n",
    "            - logw: The log-weight of `x_curr`.\n",
    "        \"\"\"\n",
    "        if self._bootstrap:\n",
    "            x_curr, logw = super().pf_step(key, x_prev, y_curr, theta)\n",
    "        else:\n",
    "            omega = (theta[self._n_Rxn:(self._n_Rxn+self._n_X)] / y_curr)**2\n",
    "            x_curr, logw = self.bridge_prop(\n",
    "                key, x_prev, y_curr, theta, \n",
    "                jnp.log(y_curr), jnp.eye(4), jnp.diag(omega)\n",
    "            )\n",
    "        return x_curr, logw\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Auto-regulatory gene network from Golightly & Wilkinson (2006)\n",
    "\n",
    "In = jnp.array([[1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
    "                [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
    "                [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
    "                [0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
    "                [1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
    "                [0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
    "                [0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0.],\n",
    "                [0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0.]])\n",
    "\n",
    "Out = jnp.array([[0., 1., 0., 1., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
    "                 [0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
    "                 [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
    "                 [0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
    "                 [0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
    "                 [0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
    "                 [0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0.],\n",
    "                 [0., 0., 0., 0., 0., 0., 1., 1., 0., 0., 0., 0.]])\n",
    "\n",
    "I,G,Ii,Ig,i,g,ri,rg = (8.5,29,2,3,8,7,18,9)\n",
    "X_init = jnp.array([I,G,Ii,Ig,i,g,ri,rg])\n",
    "K1 = Ii + i\n",
    "K2 = Ig + g\n",
    "\n",
    "tau = jnp.array([0.1,0.1,0.1,0.1,0.1,0.1])\n",
    "param = jnp.array([0.08, 0.82, 0.09, 0.9, 0.25, 0.1, 0.35, 0.3, 0.1, 0.1, 0.12, 0.1])\n",
    "\n",
    "mask = jnp.array([True,  True, False, False, True,  True, True,  True])\n",
    "\n",
    "theta = jnp.concatenate((param, tau, X_init))\n",
    "gnet = StoichModel(1,2,In,Out)\n",
    "gnet_mask = StoichModel(1,2,In,Out,mask)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DeviceArray([-5.675009  , -0.20000052, -3.8000045 , -2.6550033 ,\n",
       "              0.20000064,  1.5500002 ], dtype=float32)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = jnp.array([I,G,Ii,Ig,ri,rg])\n",
    "X_mask = jnp.array([I,G,i,g,ri,rg])\n",
    "\n",
    "gnet._drift(X, theta)\n",
    "gnet_mask._drift(X_mask, theta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DeviceArray([-5.6750007 , -0.20000005, -3.8000002 , -2.6550007 ,\n",
       "              0.19999993,  1.55      ], dtype=float32)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jnp.array([param[1]*(K1-i) + param[3]*(K2-g) + param[5]*ri - param[0]*I*i - param[2]*I*g - param[10]*I , \n",
    "           param[7]*rg - param[11]*G, \n",
    "           param[1]*(K1-i) - param[0]*I*i,\n",
    "           param[3]*(K2-g) - param[2]*I*g,\n",
    "           param[4]*i - param[8]*ri,\n",
    "           param[6]*g - param[9]*rg\n",
    "          ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
