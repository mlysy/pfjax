{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "92e18cde",
   "metadata": {},
   "source": [
    "# Parallelizing the Particle Filter\n",
    "\n",
    "**Martin Lysy, University of Waterloo**\n",
    "\n",
    "**April 11, 2022**\n",
    "\n",
    "## Problem Statement\n",
    "\n",
    "Various steps in the particle filter are parallelizable across particles.  This notebook contains various experiments in how to do this most effectively.\n",
    "\n",
    "In general, we'll need to specify `n_devices` and `n_particles_per_device`.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "25177442",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"XLA_FLAGS\"] = '--xla_force_host_platform_device_count=8'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d0ed5a18",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:No GPU/TPU found, falling back to CPU. (Set TF_CPP_MIN_LOG_LEVEL=0 and rerun for more info.)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[CpuDevice(id=0),\n",
       " CpuDevice(id=1),\n",
       " CpuDevice(id=2),\n",
       " CpuDevice(id=3),\n",
       " CpuDevice(id=4),\n",
       " CpuDevice(id=5),\n",
       " CpuDevice(id=6),\n",
       " CpuDevice(id=7)]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import functools\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import jax.scipy as jsp\n",
    "from jax import random\n",
    "from jax import lax\n",
    "import pfjax as pf\n",
    "from pfjax.models import BMModel\n",
    "from pfjax.particle_filter import _lweight_to_prob, _tree_add, _tree_mean, _tree_zeros, _rm_keys\n",
    "jax.devices()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7e89f96",
   "metadata": {},
   "source": [
    "## Pmap/Vmap Version\n",
    "\n",
    "The first attempt uses only the non-experimental `jax.pmap()`.  More specifically, we `jax.vmap()` over `n_particles_per_device` on each of the `n_devices` sent to `pmap()`.\n",
    "\n",
    "**Notes:**\n",
    "\n",
    "- `pmap()` jits by default.  It would be nice to prevent this , so that things can be jitted at a higher level, e.g., if `particle_filter()` is called inside another function.\n",
    "\n",
    "    In fact, seems that `pmap()` within `jit` will destroy the `ShardedDeviceArray`.  Since `lax.scan()` jits automatically this is also the case there (though currently the sharded array is being destroyed by hand).    So perhaps we need to write a custom `resample_multinomial()` that can deal with shards."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9a572b7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def particle_filter_pmap(model, key, y_meas, theta,\n",
    "                         n_devices,\n",
    "                         n_particles_per_device,\n",
    "                         particle_sampler=pf.particle_resample,\n",
    "                         history=False,\n",
    "                         accumulator=None):\n",
    "    \"\"\"\n",
    "    Apply particle filter for given value of `theta`.\n",
    "\n",
    "    Full documentation in pfjax package.\n",
    "    \"\"\"\n",
    "    n_obs = y_meas.shape[0]\n",
    "    n_particles = n_devices * n_particles_per_device\n",
    "    has_acc = accumulator is not None\n",
    "\n",
    "    # internal functions for vectorizing\n",
    "    def pf_step(key, x_prev, y_curr):\n",
    "        return model.pf_step(key=key, x_prev=x_prev, y_curr=y_curr, theta=theta)\n",
    "\n",
    "    def pf_init(key):\n",
    "        return model.pf_init(key=key, y_init=y_meas[0], theta=theta)\n",
    "\n",
    "    def pf_acc(acc_prev, x_prev, x_curr, y_curr):\n",
    "        return _tree_add(\n",
    "            tree1=acc_prev,\n",
    "            tree2=accumulator(\n",
    "                x_prev=x_prev, x_curr=x_curr, y_curr=y_curr, theta=theta\n",
    "            )\n",
    "        )\n",
    "\n",
    "    # reshape first two dimensions to one dimension\n",
    "    def reshape_1d(x):\n",
    "        return x.reshape((-1,) + x.shape[2:])\n",
    "\n",
    "    # reshape first dimension into n_devices x n_particles_per_device\n",
    "    def reshape_2d(x):\n",
    "        return x.reshape((n_devices, n_particles_per_device) + x.shape[1:])\n",
    "\n",
    "    # lax.scan setup\n",
    "    # scan function\n",
    "    def filter_step(carry, t):\n",
    "        # sample particles from previous time point\n",
    "        key, subkey = random.split(carry[\"key\"])\n",
    "        new_particles = particle_sampler(\n",
    "            key=subkey,\n",
    "            x_particles_prev=reshape_1d(carry[\"x_particles\"]),\n",
    "            logw=reshape_1d(carry[\"logw\"])\n",
    "        )\n",
    "        # update particles to current time point (and get weights)\n",
    "        key, *subkeys = random.split(key, num=n_particles+1)\n",
    "        x_particles, logw = jax.pmap(\n",
    "            jax.vmap(pf_step, in_axes=(0, 0, None)),\n",
    "            in_axes=(0, 0, None)\n",
    "        )(reshape_2d(jnp.array(subkeys)),\n",
    "          reshape_2d(new_particles[\"x_particles\"]),\n",
    "          y_meas[t])\n",
    "        if has_acc:\n",
    "            # accumulate expectation\n",
    "            acc_curr = jax.pmap(\n",
    "                jax.vmap(pf_acc, in_axes=(0, 0, 0, None)),\n",
    "                in_axes=(0, 0, 0, None)\n",
    "            )(carry[\"accumulate_out\"], \n",
    "              reshape_2d(new_particles[\"x_particles\"]),\n",
    "              x_particles, \n",
    "              y_meas[t])\n",
    "        # output\n",
    "        res_carry = {\n",
    "            \"x_particles\": x_particles,\n",
    "            \"logw\": logw,\n",
    "            \"key\": key,\n",
    "            \"loglik\": carry[\"loglik\"] + jsp.special.logsumexp(logw),\n",
    "            \"resample_out\": _rm_keys(new_particles, [\"x_particles\", \"logw\"])\n",
    "        }\n",
    "        if has_acc:\n",
    "            res_carry[\"accumulate_out\"] = acc_curr\n",
    "        res_stack = _rm_keys(res_carry, [\"key\", \"loglik\"]) if history else None\n",
    "        return res_carry, res_stack\n",
    "    # scan initial value\n",
    "    key, *subkeys = random.split(key, num=n_particles+1)\n",
    "    x_particles, logw = jax.pmap(\n",
    "        jax.vmap(pf_init)\n",
    "    )(reshape_2d(jnp.array(subkeys)))\n",
    "    # dummy initialization for resample\n",
    "    init_resample = particle_sampler(\n",
    "        key=key,\n",
    "        x_particles_prev=reshape_1d(x_particles),\n",
    "        logw=reshape_1d(logw)\n",
    "    )\n",
    "    init_resample = _rm_keys(init_resample, [\"x_particles\", \"logw\"])\n",
    "    init_resample = _tree_zeros(init_resample)\n",
    "    if has_acc:\n",
    "        # dummy initialization for accumulate\n",
    "        init_acc = jax.pmap(\n",
    "            jax.vmap(accumulator, in_axes=(0, 0, 0, None, None)),\n",
    "            in_axes=(0, 0, None, None)\n",
    "        )(x_particles, x_particles, y_meas[0], theta)\n",
    "        init_acc = _tree_zeros(init_acc)\n",
    "    filter_init = {\n",
    "        \"x_particles\": x_particles,\n",
    "        \"logw\": logw,\n",
    "        \"loglik\": jsp.special.logsumexp(logw),\n",
    "        \"key\": key,\n",
    "        \"resample_out\": init_resample\n",
    "    }\n",
    "    if has_acc:\n",
    "        filter_init[\"accumulate_out\"] = init_acc\n",
    "    # lax.scan itself\n",
    "    last, full = lax.scan(filter_step, filter_init, jnp.arange(1, n_obs))\n",
    "    if history:\n",
    "        # append initial values of x_particles and logw\n",
    "        full[\"x_particles\"] = jnp.concatenate([\n",
    "            filter_init[\"x_particles\"][None], full[\"x_particles\"]\n",
    "        ])\n",
    "        full[\"logw\"] = jnp.concatenate([\n",
    "            filter_init[\"logw\"][None], full[\"logw\"]\n",
    "        ])\n",
    "    else:\n",
    "        full = last\n",
    "        if has_acc:\n",
    "            # weighted average of accumulated values\n",
    "            full[\"accumulate_out\"] = _tree_mean(\n",
    "                tree=full[\"accumulate_out\"],\n",
    "                logw=full[\"logw\"]\n",
    "            )\n",
    "    # calculate loglikelihood\n",
    "    full[\"loglik\"] = last[\"loglik\"] - n_obs * jnp.log(n_particles)\n",
    "    return full"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "41016f84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate data\n",
    "key = random.PRNGKey(0)\n",
    "# parameter values\n",
    "mu = 5\n",
    "sigma = 1\n",
    "tau = .1\n",
    "theta = jnp.array([mu, sigma, tau])\n",
    "# data specification\n",
    "dt = .1\n",
    "n_obs = 5\n",
    "x_init = jnp.array(0.)\n",
    "bm_model = BMModel(dt=dt)\n",
    "# simulate without for-loop\n",
    "y_meas, x_state = pf.simulate(bm_model, key, n_obs, x_init, theta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b927df0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# particle filter specification\n",
    "n_devices = 2\n",
    "n_particles_per_device = 5\n",
    "n_particles = n_devices * n_particles_per_device\n",
    "\n",
    "pf_serial = jax.jit(functools.partial(pf.particle_filter2,\n",
    "                                      model=bm_model, y_meas=y_meas,\n",
    "                                      n_particles=n_particles, history=True))\n",
    "\n",
    "pf_pmap = jax.jit(functools.partial(particle_filter_pmap,\n",
    "                                    model=bm_model, y_meas=y_meas, n_devices=n_devices,\n",
    "                                    n_particles_per_device=n_particles_per_device, history=True))\n",
    "\n",
    "pf_out = pf_serial(theta=theta, key=key)\n",
    "\n",
    "pf_out2 = pf_pmap(theta=theta, key=key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b81d4eb8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DeviceArray([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "             0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "             0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "             0., 0., 0., 0., 0.], dtype=float64)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pf_out[\"x_particles\"].ravel() - pf_out2[\"x_particles\"].ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5d6fd065",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24.5 µs ± 248 ns per loop (mean ± std. dev. of 7 runs, 10000 loops each)\n",
      "289 µs ± 18.7 µs per loop (mean ± std. dev. of 7 runs, 1000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit pf_serial(theta=theta, key=key)\n",
    "%timeit pf_pmap(theta=theta, key=key)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84595b4b",
   "metadata": {},
   "source": [
    "## Scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d62e9dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convolve(x, w):\n",
    "    \"\"\"\n",
    "    Convolve x with w.\n",
    "    \n",
    "    Must have `len(x) >= len(w)`.\n",
    "    \"\"\"\n",
    "    output = []\n",
    "    for i in jnp.arange(0, len(x)-len(w)+1):\n",
    "        output.append(jnp.dot(x[i:i+len(w)], w))\n",
    "    return jnp.array(output)\n",
    "\n",
    "jconvolve = jax.jit(convolve) # jitted version\n",
    "\n",
    "# test from doc\n",
    "x = jnp.arange(5)\n",
    "w = jnp.array([2., 3., 4.])\n",
    "\n",
    "convolve(x, w)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57cde5d1",
   "metadata": {},
   "source": [
    "## Timings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b14984a",
   "metadata": {},
   "outputs": [],
   "source": [
    "key = jax.random.PRNGKey(0)\n",
    "nx = 200\n",
    "nw = 100\n",
    "\n",
    "x = jax.random.normal(key, (nx,))\n",
    "w = jax.random.normal(key, (nw,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fea2819",
   "metadata": {},
   "outputs": [],
   "source": [
    "# unjitted\n",
    "%timeit convolve(x,w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ea9d48a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# jitted\n",
    "%timeit jconvolve(x,w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00e1f779",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
