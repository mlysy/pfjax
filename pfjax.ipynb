{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Particle Filter with JAX\n",
    "\n",
    "## Notation\n",
    "\n",
    "### Functions\n",
    "\n",
    "- `state_lpdf(x_curr, x_last, theta)`: Log-density of $p(x_t | x_{t-1}, \\theta)$.\n",
    "- `state_sample(x_last, theta)`: Sample from $p(x_t | x_{t-1}, \\theta)$.\n",
    "- `meas_lpdf(y_curr, x_curr, theta)`: Log-density of $p(y_t | x_t, \\theta)$.\n",
    "- `meas_sample(x_curr, theta)`: Sample from $p(y_t | x_t, \\theta)$.\n",
    "\n",
    "### Dimensions\n",
    "\n",
    "- `n_obs`: Number of time points.\n",
    "- `n_state`: Number of state dimensions.\n",
    "- `n_meas`: Number of measured dimensions.\n",
    "- `n_particle`: Number of particles."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example: Brownian motion with drift\n",
    "\n",
    "The model is\n",
    "$$\n",
    "\\newcommand{\\N}{\\mathcal{N}}\n",
    "\\newcommand{\\dt}{\\Delta t}\n",
    "\\begin{aligned}\n",
    "x_0 & \\sim \\pi(x_0) \\\\\n",
    "x_t & \\sim \\N(x_{t-1} + \\mu \\dt, \\sigma^2 \\dt) \\\\\n",
    "y_t & \\sim \\N(x_t, \\tau^2).\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "Therefore, `n_state` = `n_meas` = 1.  \n",
    "\n",
    "Note that with $\\pi(x_0) \\propto 1$, we may condition on $y_0$ and obtain $x_0 \\mid y_0 \\sim \\N(y_0, \\tau^2)$.\n",
    "\n",
    "### Using **NumPy** and **SciPy**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load bm_model.py\n",
    "\"\"\"\n",
    "Brownian motion state space model.\n",
    "\n",
    "The model is:\n",
    "\n",
    "```\n",
    "x_0 ~ pi(x_0) \\propto 1\n",
    "x_t ~ N(x_{t-1} + mu * dt, sigma * sqrt(dt))\n",
    "y_t ~ N(x_t, tau)\n",
    "```\n",
    "\n",
    "The parameter values are `theta = (mu, sigma, tau)`, and `dt` is a global constant.\n",
    "\"\"\"\n",
    "\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import scipy.stats\n",
    "\n",
    "\n",
    "# state-space dimensions\n",
    "n_meas = 1\n",
    "n_state = 1\n",
    "\n",
    "\n",
    "def state_lpdf(x_curr, x_prev, theta):\n",
    "    \"\"\"\n",
    "    Calculates the log-density of `p(x_curr | x_prev, theta)`.\n",
    "\n",
    "    Args:\n",
    "        x_curr: State variable at current time `t`.\n",
    "        x_prev: State variable at previous time `t-1`.\n",
    "        theta: Parameter value.\n",
    "\n",
    "    Returns:\n",
    "        The log-density of `p(x_curr | x_prev, theta)`.\n",
    "    \"\"\"\n",
    "    mu = theta[0]\n",
    "    sigma = theta[1]\n",
    "    return sp.stats.norm.logpdf(x_curr, loc=x_prev + mu * dt, scale=sigma * np.sqrt(dt))\n",
    "\n",
    "\n",
    "def state_sample(x_prev, theta):\n",
    "    \"\"\"\n",
    "    Samples from `x_curr ~ p(x_curr | x_prev, theta)`.\n",
    "\n",
    "    Args:\n",
    "        x_prev: State variable at previous time `t-1`.\n",
    "        theta: Parameter value.\n",
    "\n",
    "    Returns:\n",
    "        Sample of the state variable at current time `t`: `x_curr ~ p(x_curr | x_prev, theta)`.\n",
    "    \"\"\"\n",
    "    mu = theta[0]\n",
    "    sigma = theta[1]\n",
    "    return sp.stats.norm.rvs(loc=x_prev + mu * dt, scale=sigma * np.sqrt(dt))\n",
    "\n",
    "\n",
    "def meas_lpdf(y_curr, x_curr, theta):\n",
    "    \"\"\"\n",
    "    Log-density of `p(y_curr | x_curr, theta)`.\n",
    "\n",
    "    Args:\n",
    "        y_curr: Measurement variable at current time `t`.\n",
    "        x_curr: State variable at current time `t`.\n",
    "        theta: Parameter value.\n",
    "\n",
    "    Returns\n",
    "        The log-density of `p(x_curr | x_prev, theta)`.\n",
    "    \"\"\"\n",
    "    tau = theta[2]\n",
    "    return sp.stats.norm.logpdf(y_curr, loc=x_curr, scale=tau)\n",
    "\n",
    "\n",
    "def meas_sample(x_curr, theta):\n",
    "    \"\"\"\n",
    "    Sample from `p(y_curr | x_curr, theta)`.\n",
    "\n",
    "    Args:\n",
    "        x_curr: State variable at current time `t`.\n",
    "        theta: Parameter value.\n",
    "\n",
    "    Returns:\n",
    "        Sample of the measurement variable at current time `t`: `y_curr ~ p(y_curr | x_curr, theta)`.\n",
    "    \"\"\"\n",
    "    tau = theta[2]\n",
    "    return sp.stats.norm.rvs(loc=x_curr, scale=tau)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load particle_filter.py\n",
    "\"\"\"\n",
    "Prototype for particle filter using NumPy/SciPy.\n",
    "\n",
    "The API requires the user to define the following functions:\n",
    "\n",
    "- `state_lpdf(x_curr, x_last, theta)`: Log-density of `p(x_t | x_{t-1}, theta)`.\n",
    "- `state_sample(x_last, theta)`: Sample from `x_curr ~ p(x_t | x_{t-1}, theta)`.\n",
    "- `meas_lpdf(y_curr, x_curr, theta)`: Log-density of `p(y_t | x_t, theta)`.\n",
    "- `meas_sample(x_curr, theta)`: Sample from `y_curr ~ p(y_t | x_t, theta)`.\n",
    "\n",
    "For now, additional inputs are specified as global constants.\n",
    "\n",
    "The provided functions are:\n",
    "\n",
    "- `meas_sim(n_obs, x_init, theta)`: Obtain a sample from `y_meas = (y_1, ..., y_T)` and `x_state = (x_1, ..., x_T)`.\n",
    "- `particle_filter(y_meas, theta, n_particles): Run the particle filter.\n",
    "- `particle_loglik(logw_particles)`: Compute the particle filter marginal loglikelihoood.\n",
    "- `particle_smooth(logw, X_particles, ancestor_particles, n_sample)`: Posterior sampling from the particle filter distribution of `p(x_state | y_meas, theta)`.\n",
    "- `particle_resample(logw)`: A rudimentary particle resampling method.\n",
    "\"\"\"\n",
    "\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import scipy.stats\n",
    "\n",
    "\n",
    "def meas_sim(n_obs, x_init, theta):\n",
    "    \"\"\"\n",
    "    Simulate data from the state-space model.\n",
    "\n",
    "    Args:\n",
    "        n_obs: Number of observations to generate.\n",
    "        x_init: Initial state value at time `t = 0`.\n",
    "        theta: Parameter value.\n",
    "\n",
    "    Returns:\n",
    "        y_meas: The sequence of measurement variables `y_meas = (y_1, ..., y_T)`, where `T = n_obs`.\n",
    "        x_state: The sequence of state variables `x_state = (x_1, ..., x_T)`, where `T = n_obs`.\n",
    "    \"\"\"\n",
    "    y_meas = np.zeros((n_obs, n_meas))\n",
    "    x_state = np.zeros((n_obs, n_state))\n",
    "    x_prev = x_init\n",
    "    for t in range(n_obs):\n",
    "        x_state[t] = state_sample(x_prev, theta)\n",
    "        y_meas[t] = meas_sample(x_state[t], theta)\n",
    "        x_prev = x_state[t]\n",
    "    return y_meas, x_state\n",
    "\n",
    "\n",
    "def particle_resample(logw):\n",
    "    \"\"\"\n",
    "    Particle resampler.\n",
    "\n",
    "    This basic one just does a multinomial sampler, i.e., sample with replacement proportional to weights.\n",
    "\n",
    "    Args:\n",
    "        logw: Vector of `n_particles` unnormalized log-weights.\n",
    "\n",
    "    Returns:\n",
    "        Vector of `n_particles` integers between 0 and `n_particles-1`, sampled with replacement with probability vector `exp(logw) / sum(exp(logw))`.\n",
    "    \"\"\"\n",
    "    wgt = np.exp(logw - np.max(logw))\n",
    "    prob = wgt / np.sum(wgt)\n",
    "    n_particles = logw.size\n",
    "    return np.random.choice(np.arange(n_particles), size=n_particles, p=prob)\n",
    "\n",
    "\n",
    "def particle_filter(y_meas, theta, n_particles):\n",
    "    \"\"\"\n",
    "    Apply particle filter for given value of `theta`.\n",
    "\n",
    "    Closely follows Algorithm 2 of https://arxiv.org/pdf/1306.3277.pdf.\n",
    "\n",
    "    FIXME: Uses a hard-coded prior for initial state variable `x_state[0]`.  Need to make this more general.\n",
    "\n",
    "    Args:\n",
    "        y_meas: The sequence of `n_obs` measurement variables `y_meas = (y_1, ..., y_T)`, where `T = n_obs`.\n",
    "        theta: Parameter value.\n",
    "        n_particles: Number of particles.\n",
    "\n",
    "    Returns:\n",
    "        A dictionary with elements:\n",
    "            - `X_particles`: An `ndarray` with leading dimensions `(n_obs, n_particles)` containing the state variable particles.\n",
    "            - `logw_particles`: An `ndarray` of shape `(n_obs, n_particles)` giving the unnormalized log-weights of each particle at each time point.\n",
    "            - `ancestor_particles`: An integer `ndarray` of shape `(n_obs, n_particles)` where each element gives the index of the particle's ancestor at the previous time point.  Since the first time point does not have ancestors, the first row of `ancestor_particles` contains all `-1`.\n",
    "    \"\"\"\n",
    "    # memory allocation\n",
    "    n_obs = y_meas.shape[0]\n",
    "    X_particles = np.zeros((n_obs, n_particles, n_state))\n",
    "    logw_particles = np.zeros((n_obs, n_particles))\n",
    "    ancestor_particles = np.zeros((n_obs, n_particles), dtype=int)\n",
    "    ancestor_particles[0] = -1  # initial particles have no ancestors\n",
    "    # initial time point\n",
    "    # FIXME: Hard-coded flat prior on x_0.  Make this more general.\n",
    "    for i_part in range(n_particles):\n",
    "        X_particles[0, i_part, :] = meas_sample(y_meas[0, :], theta)\n",
    "        # sample directly from posterior p(x_0 | y_0, theta)\n",
    "        logw_particles[0, i_part] = 0.\n",
    "    # subsequent time points\n",
    "    for t in range(1, n_obs):\n",
    "        # resampling step\n",
    "        ancestor_particles[t] = particle_resample(logw_particles[t-1])\n",
    "        for i_part in range(n_particles):\n",
    "            X_particles[t, i_part, :] = state_sample(\n",
    "                X_particles[t-1, ancestor_particles[t, i_part], :], theta\n",
    "            )\n",
    "            logw_particles[t, i_part] = meas_lpdf(\n",
    "                y_meas[t, :], X_particles[t, i_part, :], theta\n",
    "            )\n",
    "    return {\n",
    "        \"X_particles\": X_particles,\n",
    "        \"logw_particles\": logw_particles,\n",
    "        \"ancestor_particles\": ancestor_particles\n",
    "    }\n",
    "\n",
    "\n",
    "def particle_loglik(logw_particles):\n",
    "    \"\"\"\n",
    "    Calculate particle filter marginal loglikelihood.\n",
    "\n",
    "    Args:\n",
    "        logw_particles: An `ndarray` of shape `(n_obs, n_particles)` giving the unnormalized log-weights of each particle at each time point.        \n",
    "\n",
    "    Returns:\n",
    "        Particle filter approximation of \n",
    "        ```\n",
    "        log p(y_meas | theta) = log int p(y_meas | x_state, theta) * p(x_state | theta) dx_state\n",
    "        ```\n",
    "    \"\"\"\n",
    "    return np.sum(sp.special.logsumexp(logw_particles, axis=1))\n",
    "\n",
    "\n",
    "def particle_smooth(logw, X_particles, ancestor_particles, n_sample=1):\n",
    "    \"\"\"\n",
    "    Basic particle smoothing algorithm.\n",
    "\n",
    "    Samples from posterior distribution `p(x_state | x_meas, theta)`.\n",
    "\n",
    "    Args:\n",
    "        logw: Vector of `n_particles` unnormalized log-weights at the last time point `t = n_obs`.\n",
    "        X_particles: An `ndarray` with leading dimensions `(n_obs, n_particles)` containing the state variable particles.        \n",
    "        ancestor_particles: An integer `ndarray` of shape `(n_obs, n_particles)` where each element gives the index of the particle's ancestor at the previous time point.\n",
    "        n_sample: Number of draws of `x_state` to return.\n",
    "\n",
    "    Returns:\n",
    "        An `ndarray` with leading dimension `n_sample` corresponding to as many samples from the particle filter approximation to the posterior distribution `p(x_state | x_meas, theta)`.\n",
    "    \"\"\"\n",
    "    wgt = np.exp(logw - np.max(logw))\n",
    "    prob = wgt / np.sum(wgt)\n",
    "    n_particles = logw.size\n",
    "    n_obs = X_particles.shape[0]\n",
    "    n_state = X_particles.shape[2]\n",
    "    x_state = np.zeros((n_sample, n_obs, n_state))\n",
    "    for i_samp in range(n_sample):\n",
    "        i_part = np.random.choice(np.arange(n_particles), size=1, p=prob)\n",
    "        # i_part_T = i_part\n",
    "        x_state[i_samp, n_obs-1] = X_particles[n_obs-1, i_part, :]\n",
    "        for i_obs in reversed(range(n_obs-1)):\n",
    "            i_part = ancestor_particles[i_obs+1, i_part]\n",
    "            x_state[i_samp, i_obs] = X_particles[i_obs, i_part, :]\n",
    "    return x_state  # , i_part_T\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_meas = \n",
      " [[0.76371425]\n",
      " [0.88715404]\n",
      " [1.10640127]\n",
      " [1.36352618]\n",
      " [1.95148437]]\n",
      "x_state = \n",
      " [[0.66073978]\n",
      " [0.78324502]\n",
      " [0.95774334]\n",
      " [1.35223807]\n",
      " [1.95785123]]\n",
      "pf_out = \n",
      " {'X_particles': array([[[0.77350637],\n",
      "        [0.61849112],\n",
      "        [0.78837221],\n",
      "        [0.69694015],\n",
      "        [0.75922677],\n",
      "        [0.61105708],\n",
      "        [0.81612899]],\n",
      "\n",
      "       [[1.33094042],\n",
      "        [0.83430704],\n",
      "        [1.72074152],\n",
      "        [1.00563761],\n",
      "        [1.37481499],\n",
      "        [0.7076549 ],\n",
      "        [0.93824445]],\n",
      "\n",
      "       [[1.46630755],\n",
      "        [1.76465845],\n",
      "        [1.56231864],\n",
      "        [1.49361636],\n",
      "        [1.20354607],\n",
      "        [1.34611214],\n",
      "        [1.7137133 ]],\n",
      "\n",
      "       [[1.77178989],\n",
      "        [2.2083558 ],\n",
      "        [1.99854547],\n",
      "        [1.53933115],\n",
      "        [1.86793308],\n",
      "        [1.66248025],\n",
      "        [1.62665892]],\n",
      "\n",
      "       [[2.20552559],\n",
      "        [2.04343909],\n",
      "        [1.87094663],\n",
      "        [2.28008091],\n",
      "        [2.04926174],\n",
      "        [2.60712631],\n",
      "        [2.51485203]]]), 'logw_particles': array([[  0.        ,   0.        ,   0.        ,   0.        ,\n",
      "          0.        ,   0.        ,   0.        ],\n",
      "       [ -8.46367107,   1.24400632, -33.35975834,   0.68172872,\n",
      "        -10.50701381,  -0.22735043,   1.25313504],\n",
      "       [ -5.09297982, -20.28147908,  -9.00938577,  -6.11312985,\n",
      "          0.91179095,  -1.48941863, -17.05774859],\n",
      "       [ -6.95031643, -34.30320751, -18.77882868,  -0.16172279,\n",
      "        -11.33766953,  -3.0850303 ,  -2.07829546],\n",
      "       [ -1.84320045,   0.960863  ,   1.05933016,  -4.01513772,\n",
      "          0.90562583, -20.10967104, -14.48550963]]), 'ancestor_particles': array([[-1, -1, -1, -1, -1, -1, -1],\n",
      "       [ 1,  3,  2,  1,  6,  5,  3],\n",
      "       [ 1,  1,  6,  1,  1,  5,  6],\n",
      "       [ 5,  4,  4,  4,  5,  4,  4],\n",
      "       [ 3,  3,  3,  3,  6,  3,  3]])}\n",
      "pf_loglik = \n",
      " 7.344373664014883\n",
      "X_state = \n",
      " [[[0.69694015]\n",
      "  [0.83430704]\n",
      "  [1.20354607]\n",
      "  [1.53933115]\n",
      "  [1.87094663]]\n",
      "\n",
      " [[0.69694015]\n",
      "  [0.83430704]\n",
      "  [1.20354607]\n",
      "  [1.62665892]\n",
      "  [2.04926174]]\n",
      "\n",
      " [[0.69694015]\n",
      "  [0.83430704]\n",
      "  [1.20354607]\n",
      "  [1.53933115]\n",
      "  [1.87094663]]\n",
      "\n",
      " [[0.69694015]\n",
      "  [0.83430704]\n",
      "  [1.20354607]\n",
      "  [1.53933115]\n",
      "  [2.04343909]]\n",
      "\n",
      " [[0.69694015]\n",
      "  [0.83430704]\n",
      "  [1.20354607]\n",
      "  [1.62665892]\n",
      "  [2.04926174]]\n",
      "\n",
      " [[0.69694015]\n",
      "  [0.83430704]\n",
      "  [1.20354607]\n",
      "  [1.53933115]\n",
      "  [1.87094663]]\n",
      "\n",
      " [[0.69694015]\n",
      "  [0.83430704]\n",
      "  [1.20354607]\n",
      "  [1.53933115]\n",
      "  [1.87094663]]\n",
      "\n",
      " [[0.69694015]\n",
      "  [0.83430704]\n",
      "  [1.20354607]\n",
      "  [1.62665892]\n",
      "  [2.04926174]]\n",
      "\n",
      " [[0.69694015]\n",
      "  [0.83430704]\n",
      "  [1.20354607]\n",
      "  [1.62665892]\n",
      "  [2.04926174]]\n",
      "\n",
      " [[0.69694015]\n",
      "  [0.83430704]\n",
      "  [1.20354607]\n",
      "  [1.53933115]\n",
      "  [1.87094663]]\n",
      "\n",
      " [[0.69694015]\n",
      "  [0.83430704]\n",
      "  [1.20354607]\n",
      "  [1.62665892]\n",
      "  [2.04926174]]]\n"
     ]
    }
   ],
   "source": [
    "# %load test_particle_filter.py\n",
    "# parameter values\n",
    "mu = 5\n",
    "sigma = 1\n",
    "tau = .1\n",
    "theta = np.array([mu, sigma, tau])\n",
    "\n",
    "# data specification\n",
    "dt = .1\n",
    "n_obs = 5\n",
    "x_init = np.array([0.])\n",
    "\n",
    "# simulate data\n",
    "y_meas, x_state = meas_sim(n_obs, x_init, theta)\n",
    "\n",
    "print(\"y_meas = \\n\", y_meas)\n",
    "print(\"x_state = \\n\", x_state)\n",
    "\n",
    "n_particles = 7\n",
    "pf_out = particle_filter(y_meas, theta, n_particles)\n",
    "pf_out = particle_filter(y_meas, theta, n_particles)\n",
    "pf_out = particle_filter(y_meas, theta, n_particles)\n",
    "\n",
    "print(\"pf_out = \\n\", pf_out)\n",
    "\n",
    "# calculate marginal loglikelihood\n",
    "pf_loglik = particle_loglik(pf_out[\"logw_particles\"])\n",
    "\n",
    "print(\"pf_loglik = \\n\", pf_loglik)\n",
    "\n",
    "# sample from posterior `p(x_{0:T} | y_{0:T}, theta)`\n",
    "n_sample = 11\n",
    "X_state = particle_smooth(\n",
    "    pf_out[\"logw_particles\"][n_obs-1],\n",
    "    pf_out[\"X_particles\"],\n",
    "    pf_out[\"ancestor_particles\"],\n",
    "    n_sample\n",
    ")\n",
    "\n",
    "print(\"X_state = \\n\", X_state)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using JAX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load bm_model_jax.py\n",
    "\"\"\"\n",
    "Brownian motion state space model in JAX.\n",
    "\"\"\"\n",
    "\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import jax.scipy as jsp\n",
    "from jax import random\n",
    "\n",
    "\n",
    "# state-space dimensions\n",
    "n_meas = 1\n",
    "n_state = 1\n",
    "\n",
    "\n",
    "def state_lpdf(x_curr, x_prev, theta):\n",
    "    \"\"\"\n",
    "    Calculates the log-density of `p(x_curr | x_prev, theta)`.\n",
    "\n",
    "    Args:\n",
    "        x_curr: State variable at current time `t`.\n",
    "        x_prev: State variable at previous time `t-1`.\n",
    "        theta: Parameter value.\n",
    "\n",
    "    Returns:\n",
    "        The log-density of `p(x_curr | x_prev, theta)`.\n",
    "    \"\"\"\n",
    "    mu = theta[0]\n",
    "    sigma = theta[1]\n",
    "    return jsp.stats.norm.logpdf(x_curr, loc=x_prev + mu * dt, scale=sigma * jnp.sqrt(dt))\n",
    "\n",
    "\n",
    "def state_sample(x_prev, theta, key):\n",
    "    \"\"\"\n",
    "    Samples from `x_curr ~ p(x_curr | x_prev, theta)`.\n",
    "\n",
    "    Args:\n",
    "        x_prev: State variable at previous time `t-1`.\n",
    "        theta: Parameter value.\n",
    "        key: PRNG key.\n",
    "\n",
    "    Returns:\n",
    "        Sample of the state variable at current time `t`: `x_curr ~ p(x_curr | x_prev, theta)`.\n",
    "    \"\"\"\n",
    "    mu = theta[0]\n",
    "    sigma = theta[1]\n",
    "    x_mean = x_prev + mu * dt\n",
    "    x_sd = sigma * jnp.sqrt(dt)\n",
    "    return x_mean + x_sd * random.normal(key=key)\n",
    "\n",
    "\n",
    "def meas_lpdf(y_curr, x_curr, theta):\n",
    "    \"\"\"\n",
    "    Log-density of `p(y_curr | x_curr, theta)`.\n",
    "\n",
    "    Args:\n",
    "        y_curr: Measurement variable at current time `t`.\n",
    "        x_curr: State variable at current time `t`.\n",
    "        theta: Parameter value.\n",
    "\n",
    "    Returns\n",
    "        The log-density of `p(x_curr | x_prev, theta)`.\n",
    "    \"\"\"\n",
    "    tau = theta[2]\n",
    "    return jsp.stats.norm.logpdf(y_curr, loc=x_curr, scale=tau)\n",
    "\n",
    "\n",
    "def meas_sample(x_curr, theta, key):\n",
    "    \"\"\"\n",
    "    Sample from `p(y_curr | x_curr, theta)`.\n",
    "\n",
    "    Args:\n",
    "        x_curr: State variable at current time `t`.\n",
    "        theta: Parameter value.\n",
    "        key: PRNG key.\n",
    "\n",
    "    Returns:\n",
    "        Sample of the measurement variable at current time `t`: `y_curr ~ p(y_curr | x_curr, theta)`.\n",
    "    \"\"\"\n",
    "    tau = theta[2]\n",
    "    return x_curr + tau * random.normal(key=key)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load particle_filter_jax.py\n",
    "\"\"\"\n",
    "Particle filter in JAX.\n",
    "\n",
    "Uses the same API as NumPy/SciPy version.\n",
    "\"\"\"\n",
    "\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import jax.scipy as jsp\n",
    "from jax import random\n",
    "\n",
    "\n",
    "def meas_sim(n_obs, x_init, theta, key):\n",
    "    \"\"\"\n",
    "    Simulate data from the state-space model.\n",
    "\n",
    "    Args:\n",
    "        n_obs: Number of observations to generate.\n",
    "        x_init: Initial state value at time `t = 0`.\n",
    "        theta: Parameter value.\n",
    "        key: PRNG key.\n",
    "\n",
    "    Returns:\n",
    "        y_meas: The sequence of measurement variables `y_meas = (y_1, ..., y_T)`, where `T = n_obs`.\n",
    "        x_state: The sequence of state variables `x_state = (x_1, ..., x_T)`, where `T = n_obs`.\n",
    "    \"\"\"\n",
    "    y_meas = jnp.zeros((n_obs, n_meas))\n",
    "    x_state = jnp.zeros((n_obs, n_state))\n",
    "    x_prev = x_init\n",
    "    for t in range(n_obs):\n",
    "        key, *subkeys = random.split(key, num=3)\n",
    "        x_state = x_state.at[t].set(state_sample(x_prev, theta, subkeys[0]))\n",
    "        y_meas = y_meas.at[t].set(meas_sample(x_state[t], theta, subkeys[1]))\n",
    "        x_prev = x_state[t]\n",
    "    return y_meas, x_state\n",
    "\n",
    "\n",
    "def particle_resample(logw, key):\n",
    "    \"\"\"\n",
    "    Particle resampler.\n",
    "\n",
    "    This basic one just does a multinomial sampler, i.e., sample with replacement proportional to weights.\n",
    "\n",
    "    Args:\n",
    "        logw: Vector of `n_particles` unnormalized log-weights.\n",
    "        key: PRNG key.\n",
    "\n",
    "    Returns:\n",
    "        Vector of `n_particles` integers between 0 and `n_particles-1`, sampled with replacement with probability vector `exp(logw) / sum(exp(logw))`.\n",
    "    \"\"\"\n",
    "    wgt = jnp.exp(logw - jnp.max(logw))\n",
    "    prob = wgt / jnp.sum(wgt)\n",
    "    n_particles = logw.size\n",
    "    return random.choice(key,\n",
    "                         a=jnp.arange(n_particles), shape=(n_particles,), p=prob)\n",
    "\n",
    "\n",
    "def particle_filter(y_meas, theta, n_particles, key):\n",
    "    \"\"\"\n",
    "    Apply particle filter for given value of `theta`.\n",
    "\n",
    "    Closely follows Algorithm 2 of https://arxiv.org/pdf/1306.3277.pdf.\n",
    "\n",
    "    FIXME: Uses a hard-coded prior for initial state variable `x_state[0]`.  Need to make this more general.\n",
    "\n",
    "    Args:\n",
    "        y_meas: The sequence of `n_obs` measurement variables `y_meas = (y_1, ..., y_T)`, where `T = n_obs`.\n",
    "        theta: Parameter value.\n",
    "        n_particles: Number of particles.\n",
    "        key: PRNG key.\n",
    "\n",
    "    Returns:\n",
    "        A dictionary with elements:\n",
    "            - `X_particles`: An `ndarray` with leading dimensions `(n_obs, n_particles)` containing the state variable particles.\n",
    "            - `logw_particles`: An `ndarray` of shape `(n_obs, n_particles)` giving the unnormalized log-weights of each particle at each time point.\n",
    "            - `ancestor_particles`: An integer `ndarray` of shape `(n_obs, n_particles)` where each element gives the index of the particle's ancestor at the previous time point.  Since the first time point does not have ancestors, the first row of `ancestor_particles` contains all `-1`.\n",
    "    \"\"\"\n",
    "    # memory allocation\n",
    "    n_obs = y_meas.shape[0]\n",
    "    X_particles = jnp.zeros((n_obs, n_particles, n_state))\n",
    "    logw_particles = jnp.zeros((n_obs, n_particles))\n",
    "    ancestor_particles = jnp.zeros((n_obs, n_particles), dtype=int)\n",
    "    # initial particles have no ancestors\n",
    "    ancestor_particles = ancestor_particles.at[0].set(-1)\n",
    "    # initial time point\n",
    "    # FIXME: Hard-coded flat prior on x_0.  Make this more general.\n",
    "    key, *subkeys = random.split(key, num=n_particles+1)\n",
    "    X_particles = X_particles.at[0].set(\n",
    "        jax.vmap(lambda k: meas_sample(y_meas[0], theta, k))(\n",
    "            jnp.array(subkeys)\n",
    "        )\n",
    "    )\n",
    "    # sample directly from posterior p(x_0 | y_0, theta)\n",
    "    logw_particles = logw_particles.at[0].set(0.)\n",
    "    # subsequent time points\n",
    "    for t in range(1, n_obs):\n",
    "        # resampling step\n",
    "        key, subkey = random.split(key)\n",
    "        ancestor_particles = ancestor_particles.at[t].set(\n",
    "            particle_resample(logw_particles[t-1], subkey)\n",
    "        )\n",
    "        # update\n",
    "        key, *subkeys = random.split(key, num=n_particles+1)\n",
    "        X_particles = X_particles.at[t].set(\n",
    "            jax.vmap(lambda xs, k: state_sample(xs, theta, k))(\n",
    "                X_particles[t-1, ancestor_particles[t]], jnp.array(subkeys)\n",
    "            )\n",
    "        )\n",
    "        logw_particles = logw_particles.at[t].set(\n",
    "            jnp.squeeze(\n",
    "                jax.vmap(lambda xs: meas_lpdf(y_meas[t], xs, theta))(\n",
    "                    X_particles[t]\n",
    "                )\n",
    "            )\n",
    "        )\n",
    "    return {\n",
    "        \"X_particles\": X_particles,\n",
    "        \"logw_particles\": logw_particles,\n",
    "        \"ancestor_particles\": ancestor_particles\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5.  1.  0.1]\n",
      "y_meas = \n",
      " [[0.44947725]\n",
      " [0.68188113]\n",
      " [0.91331539]\n",
      " [1.05404084]\n",
      " [1.68557842]]\n",
      "x_state = \n",
      " [[0.4394778 ]\n",
      " [0.60337457]\n",
      " [0.88978651]\n",
      " [1.07383932]\n",
      " [1.44880131]]\n",
      "pf_out = \n",
      " {'X_particles': DeviceArray([[[0.38734738],\n",
      "              [0.42851383],\n",
      "              [0.44831397],\n",
      "              [0.48654838],\n",
      "              [0.68515367],\n",
      "              [0.43273745],\n",
      "              [0.57517652]],\n",
      "\n",
      "             [[1.28661928],\n",
      "              [1.42292051],\n",
      "              [1.3405227 ],\n",
      "              [1.04493578],\n",
      "              [0.83283796],\n",
      "              [0.76433738],\n",
      "              [0.3247642 ]],\n",
      "\n",
      "             [[1.11614122],\n",
      "              [1.18730814],\n",
      "              [1.48856869],\n",
      "              [0.56884518],\n",
      "              [0.97734757],\n",
      "              [1.51114774],\n",
      "              [1.73332512]],\n",
      "\n",
      "             [[1.44909828],\n",
      "              [1.4053407 ],\n",
      "              [1.56266414],\n",
      "              [1.74703783],\n",
      "              [1.70365507],\n",
      "              [2.07926504],\n",
      "              [1.35491909]],\n",
      "\n",
      "             [[1.77026707],\n",
      "              [1.55614652],\n",
      "              [1.61751625],\n",
      "              [1.13581634],\n",
      "              [2.09505906],\n",
      "              [1.62762524],\n",
      "              [1.67287277]]], dtype=float64), 'logw_particles': DeviceArray([[  0.        ,   0.        ,   0.        ,   0.        ,\n",
      "                0.        ,   0.        ,   0.        ],\n",
      "             [-16.90176486, -26.07332144, -20.30678932,  -5.20678754,\n",
      "                0.24424832,   1.04369489,  -4.99297857],\n",
      "             [ -0.67326922,  -2.36995469, -15.16217131,  -4.54933968,\n",
      "                1.17864058, -16.4865292 , -32.23715087],\n",
      "             [ -6.41987217,  -4.78693292, -11.55123651, -22.62859483,\n",
      "              -19.71628535, -51.17058602,  -3.14273938],\n",
      "             [  1.02503818,   0.54601583,   1.15202363, -13.72827059,\n",
      "               -7.00007347,   1.21571805,   1.37557489]], dtype=float64), 'ancestor_particles': DeviceArray([[-1, -1, -1, -1, -1, -1, -1],\n",
      "             [ 2,  5,  6,  1,  4,  6,  1],\n",
      "             [ 5,  5,  5,  5,  5,  4,  5],\n",
      "             [ 0,  4,  4,  4,  4,  4,  0],\n",
      "             [ 1,  6,  1,  1,  6,  6,  1]], dtype=int64)}\n",
      "max diff between pf_out and pf_out_jitted = \n",
      " {'X_particles': DeviceArray(4.4408921e-16, dtype=float64), 'logw_particles': DeviceArray(1.77635684e-14, dtype=float64), 'ancestor_particles': DeviceArray(0, dtype=int64)}\n"
     ]
    }
   ],
   "source": [
    "# %load test_particle_filter_jax.py\n",
    "key = random.PRNGKey(0)\n",
    "\n",
    "# parameter values\n",
    "mu = 5\n",
    "sigma = 1\n",
    "tau = .1\n",
    "theta = jnp.array([mu, sigma, tau])\n",
    "\n",
    "print(theta)\n",
    "\n",
    "# data specification\n",
    "dt = .1\n",
    "n_obs = 5\n",
    "x_init = jnp.array([0.])\n",
    "\n",
    "# simulate data\n",
    "key, subkey = random.split(key)\n",
    "y_meas, x_state = meas_sim(n_obs, x_init, theta, subkey)\n",
    "\n",
    "print(\"y_meas = \\n\", y_meas)\n",
    "print(\"x_state = \\n\", x_state)\n",
    "\n",
    "# run particle filter\n",
    "n_particles = 7\n",
    "key, subkey = random.split(key)\n",
    "particle_filter_jitted = jax.jit(particle_filter, static_argnums=(2,))\n",
    "pf_out = particle_filter(y_meas, theta, n_particles, subkey)\n",
    "pf_out_jitted = particle_filter_jitted(y_meas, theta, n_particles, subkey)\n",
    "\n",
    "print(\"pf_out = \\n\", pf_out)\n",
    "print(\"max diff between pf_out and pf_out_jitted = \\n\", {k:jnp.max(jnp.abs(pf_out[k] - pf_out_jitted[k])) for k in pf_out.keys()})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "116 ms ± 1.74 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%timeit particle_filter(y_meas, theta, n_particles, subkey)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "67.2 µs ± 318 ns per loop (mean ± std. dev. of 7 runs, 10000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit particle_filter_jitted(y_meas, theta, n_particles, subkey)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1726.1904761904764"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(116 * 1e-3) / (67.2 * 1e-6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DeviceArray([-0.33247287], dtype=float64)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state_lpdf(x_state[1], x_state[0], theta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.34141049],\n",
       "       [0.74321696],\n",
       "       [0.83085765],\n",
       "       [1.98326492],\n",
       "       [2.79380972]])"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import scipy as sp\n",
    "import scipy.stats\n",
    "\n",
    "def state_lpdf(x_curr, x_last, theta):\n",
    "    mu = theta[0]\n",
    "    sigma = theta[1]\n",
    "    return sp.stats.norm.logpdf(x_curr, loc = x_last + mu * dt, scale = sigma * np.sqrt(dt))\n",
    "\n",
    "\n",
    "def state_sample(x_last, theta):\n",
    "    mu = theta[0]\n",
    "    sigma = theta[1]\n",
    "    return sp.stats.norm.rvs(loc = x_last + mu * dt, scale = sigma * np.sqrt(dt))\n",
    "\n",
    "def meas_lpdf(y_curr, x_curr, theta):\n",
    "    tau = theta[2]\n",
    "    return sp.stats.norm.logpdf(y_curr, loc = x_curr, scale = tau)\n",
    "\n",
    "def meas_sample(x_curr, theta):\n",
    "    tau = theta[2]\n",
    "    return sp.stats.norm.rvs(loc = x_curr, scale = tau)\n",
    "\n",
    "# storage\n",
    "#\n",
    "# first do it column-major\n",
    "# n_state, n_particles, n_obs\n",
    "# [:,:, i_obs] represents the state of the pf  up to a given point\n",
    "# [:,i_part, i_obs] is the calculation for each particle at a given point\n",
    "#\n",
    "# now row-major\n",
    "\n",
    "# first a helper function\n",
    "def np_intarray(dims):\n",
    "    return np.reshape(np.arange(np.prod(dims))+0., dims, order = 'C')\n",
    "\n",
    "n_meas = 1\n",
    "n_state = 1\n",
    "n_particles = 7\n",
    "n_obs = 5\n",
    "n_tot = n_state * n_particles * n_obs\n",
    "#X_particles = np.arange(n_tot)\n",
    "#X_particles = np.reshape(X_particles, [n_obs, n_particles, n_state], order = 'C')\n",
    "X_particles = np_intarray([n_obs, n_particles, n_state])\n",
    "i_obs = 0\n",
    "# X_particles[i_obs]\n",
    "\n",
    "# weights\n",
    "#logw_particles = np.reshape(np.arange(n_particles * n_obs), [n_obs, n_particles])\n",
    "logw_particles = np_intarray([n_obs, n_particles])\n",
    "logw_particles[i_obs]\n",
    "\n",
    "# ancestors\n",
    "ant_particles = np_intarray([n_obs, n_particles]).astype(int)\n",
    "# first set of particles have no ancestors\n",
    "ant_particles[0] = 0\n",
    "\n",
    "# let's try it\n",
    "mu = 5\n",
    "sigma = 1\n",
    "tau = .1\n",
    "theta = np.array([mu, sigma, tau])\n",
    "dt = .1\n",
    "\n",
    "# first simulate data\n",
    "y_obs = np_intarray([n_obs, n_meas])\n",
    "x_lat = np_intarray([n_obs, n_state])\n",
    "x_prev = 0.\n",
    "for t in range(n_obs):\n",
    "    x_lat[t] = state_sample(x_prev, theta)\n",
    "    y_obs[t] = meas_sample(x_lat[t], theta)\n",
    "    x_prev = x_lat[t]\n",
    "x_lat_true = x_lat # reuse this as a variable name\n",
    "y_obs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[0.25876451]\n",
      "  [0.31918554]\n",
      "  [0.26557652]\n",
      "  [0.33072027]\n",
      "  [0.38542672]\n",
      "  [0.3636304 ]\n",
      "  [0.42153657]]\n",
      "\n",
      " [[1.11239371]\n",
      "  [1.29589014]\n",
      "  [0.95854899]\n",
      "  [1.42828306]\n",
      "  [0.53992602]\n",
      "  [0.63031026]\n",
      "  [0.71932819]]\n",
      "\n",
      " [[0.70597072]\n",
      "  [1.38912009]\n",
      "  [1.84765476]\n",
      "  [0.94279953]\n",
      "  [1.72416633]\n",
      "  [1.40544201]\n",
      "  [1.0829206 ]]\n",
      "\n",
      " [[1.48140934]\n",
      "  [1.75805587]\n",
      "  [1.10969347]\n",
      "  [1.86911294]\n",
      "  [1.16602461]\n",
      "  [1.93583039]\n",
      "  [1.02073788]]\n",
      "\n",
      " [[2.30232723]\n",
      "  [2.48872364]\n",
      "  [2.02646744]\n",
      "  [2.44285898]\n",
      "  [1.9745851 ]\n",
      "  [2.83355214]\n",
      "  [2.41469545]]]\n",
      "[[  0.           0.           0.           0.           0.\n",
      "    0.           0.        ]\n",
      " [ -5.43092725 -13.88873598  -0.93474776 -22.08213157  -0.68271372\n",
      "    0.74625047   1.3551129 ]\n",
      " [  0.60380926 -14.19920086 -50.31017205   0.75709729 -38.5163734\n",
      "  -15.12371285  -1.79313992]\n",
      " [-11.20930491  -1.15230939 -36.77270752   0.73211276 -32.01043983\n",
      "    1.2711448  -44.93926934]\n",
      " [-10.69410502  -3.27022919 -28.05706219  -4.77467435 -32.17280205\n",
      "    1.30467354  -5.80273485]]\n",
      "[[0 0 0 0 0 0 0]\n",
      " [0 4 0 1 0 5 3]\n",
      " [4 5 2 6 6 4 5]\n",
      " [0 3 3 3 0 3 3]\n",
      " [5 5 3 5 3 5 3]]\n"
     ]
    }
   ],
   "source": [
    "# now particle filter\n",
    "\n",
    "# sample from normalized weights with replacement\n",
    "def particle_resample(logw):\n",
    "    mx = np.max(logw)\n",
    "    wgt = np.exp(logw - mx)\n",
    "    n_particles = logw.size\n",
    "    #return sp.stats.multinomial.rvs(n_particles, wgt/np.sum(wgt))\n",
    "    return np.random.choice(np.arange(n_particles), size = n_particles, p = wgt / np.sum(wgt))\n",
    "\n",
    "#sp.stats.multinomial.rvs(1, [.25, .25, .25, .25], 10)\n",
    "#np.random.choice(np.arange(4), size = 10, p = [.25, .25, .25, .25])\n",
    "\n",
    "#particle_resample(np.array([0., 0., 0.]))\n",
    "\n",
    "# using flat prior on x_0 \n",
    "for i_part in range(n_particles):\n",
    "    X_particles[0,i_part,:] = meas_sample(y_obs[0,:], theta)\n",
    "    #logw_particles[0,i_part] = meas_lpdf(X_particles[0,i_part,:], y_obs[0], theta)\n",
    "    logw_particles[0,i_part] = 0. # sample directly from posterior p(x_0 | y_0, theta)\n",
    "\n",
    "# remaining observations\n",
    "for t in range(1, n_obs):\n",
    "    # resampling step\n",
    "    ant_particles[t] = particle_resample(logw_particles[t-1])\n",
    "    for i_part in range(n_particles):\n",
    "        X_particles[t,i_part,:] = state_sample(X_particles[t-1,ant_particles[t,i_part],:], theta)\n",
    "        logw_particles[t, i_part] = meas_lpdf(y_obs[t,:], X_particles[t,i_part,:], theta)\n",
    "\n",
    "print(X_particles)\n",
    "print(logw_particles)\n",
    "print(ant_particles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, 0, 0, 0, 0],\n",
       "       [2, 0, 1, 1, 1, 1, 1],\n",
       "       [0, 0, 2, 0, 0, 4, 1],\n",
       "       [0, 0, 0, 6, 1, 0, 0],\n",
       "       [0, 0, 0, 7, 0, 0, 0]])"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ant_particles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from pygments import highlight\n",
    "from pygments.lexers import PythonLexer\n",
    "from pygments.formatters import HtmlFormatter\n",
    "import IPython\n",
    "\n",
    "with open('particle_filter.py') as f:\n",
    "    code = f.read()\n",
    "\n",
    "formatter = HtmlFormatter()\n",
    "IPython.display.HTML('<style type=\"text/css\">{}</style>{}'.format(\n",
    "    formatter.get_style_defs('.highlight'),\n",
    "    highlight(code, PythonLexer(), formatter)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
